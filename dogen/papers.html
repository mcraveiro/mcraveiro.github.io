<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-02-28 Sun 11:20 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>MDE Papers</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link rel="stylesheet" href="../css/tufte.css" type="text/css" />
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="content">
<h1 class="title">MDE Papers</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgc2cf5f4">1. Systems variability modeling : a textual model mixing class and feature concepts</a>
<ul>
<li><a href="#org6278547">1.1. Variability: separated approach</a></li>
<li><a href="#org550a075">1.2. Textual notation and mixing</a></li>
<li><a href="#orge177345">1.3. Features as conceptual elements</a></li>
<li><a href="#orgb2b58a6">1.4. Product line steps</a></li>
<li><a href="#orgd21fd3f">1.5. Core assets</a></li>
<li><a href="#org9db32ad">1.6. Feature model use in MASD</a></li>
<li><a href="#org6022585">1.7. Mixing</a></li>
<li><a href="#orgb99e7f9">1.8. Feature selection</a></li>
<li><a href="#orgf2d2c4d">1.9. Complexity in configurations step</a></li>
<li><a href="#org5a305c8">1.10. Bridge between product line design and OO</a></li>
<li><a href="#org3da7625">1.11. CLAFER mixing</a></li>
<li><a href="#orgfc6194d">1.12. OOFM: Sarinho and Apolonario</a></li>
<li><a href="#org7fe40c5">1.13. ECORE feature model</a></li>
<li><a href="#orgd218188">1.14. Implementation models</a></li>
<li><a href="#org1fdd6c7">1.15. Conceptual model components</a></li>
<li><a href="#org4484dc4">1.16. TDM components</a></li>
<li><a href="#org41d0fa9">1.17. Meta-Features Model</a></li>
<li><a href="#org9fd5843">1.18. Features Meta-Model</a></li>
<li><a href="#org14df180">1.19. Application Areas</a></li>
<li><a href="#orgb322fcc">1.20. TDM has strong typing</a></li>
<li><a href="#org354ed57">1.21. TDM methodology</a></li>
<li><a href="#orgf174f3c">1.22. Conclusions</a></li>
</ul>
</li>
<li><a href="#orga7bfa29">2. A Code Generation Metamodel for ULF-Ware Generating Code for SDL and Interfacing with the Runtime Library</a>
<ul>
<li><a href="#orgbafcd5e">2.1. Intermediate model</a></li>
<li><a href="#org30ad9a8">2.2. Generality and Behaviour</a></li>
<li><a href="#org5697f97">2.3. Need for behaviour</a></li>
<li><a href="#orgae42e86">2.4. Decreasing complexity by shared meta-model</a></li>
<li><a href="#org1f56ac2">2.5. MOF</a></li>
<li><a href="#org17e90fa">2.6. Difficulties in generation</a></li>
<li><a href="#orgdc7b658">2.7. Model abstraction level is key</a></li>
<li><a href="#org1d09ca5">2.8. Commonalities for OO</a></li>
<li><a href="#org088ef1f">2.9. Multi-language and common denominators</a></li>
<li><a href="#org1c29c65">2.10. Low-level approach</a></li>
<li><a href="#orgf8cfac7">2.11. Too much detail</a></li>
<li><a href="#org1de1da6">2.12. UML Infrastructure</a></li>
<li><a href="#org289b59c">2.13. Handling of primitives</a></li>
<li><a href="#orga837c6b">2.14. Uniform interfaces to collections</a></li>
<li><a href="#orgffea59a">2.15. Function modeling</a></li>
<li><a href="#org294ade7">2.16. Predefined issues</a></li>
<li><a href="#org6882381">2.17. References</a></li>
</ul>
</li>
<li><a href="#org35cdb64">3. A Lightweight MDSD Process Applied in Small Projects</a>
<ul>
<li><a href="#org7d050c4">3.1. Important success factors</a></li>
<li><a href="#orgddca790">3.2. Range of tooling in MDE is vast</a></li>
<li><a href="#org2a2ee1e">3.3. pragmatic approach</a></li>
<li><a href="#orge8219a6">3.4. Target is small projects</a></li>
<li><a href="#orgc0d27af">3.5. Requirments</a></li>
<li><a href="#orgc2a9dc0">3.6. Activities</a></li>
<li><a href="#org945de10">3.7. MDE develppment process</a></li>
<li><a href="#org0511255">3.8. Template development</a></li>
<li><a href="#orgbafe66c">3.9. Bibliography</a></li>
</ul>
</li>
<li><a href="#orgedbd937">4. Proceso de Desarrollo de Software Mediante Herramientas MDA</a></li>
<li><a href="#org50f1446">5. Un estudio comparativo de dos herramientas MDA: OptimalJ y ArcStyler</a>
<ul>
<li><a href="#org58a6923">5.1. Important factors</a></li>
<li><a href="#org32fce9c">5.2. MDA principles</a></li>
<li><a href="#orgb7a182a">5.3. Model compiler</a></li>
<li><a href="#org8233a65">5.4. Evaluation properties</a></li>
<li><a href="#orgc786bc3">5.5. OptimalJ: Three types of models</a></li>
<li><a href="#org1f2290b">5.6. OptimalJ: Pattern types</a></li>
<li><a href="#orgdcf086d">5.7. OptimalJ: Protected regions</a></li>
<li><a href="#orgd85c4cb">5.8. ArcStyler: Cartridges</a></li>
<li><a href="#orged840af">5.9. Focus on design patterns</a></li>
<li><a href="#orgb4ccef8">5.10. Tradeoffs between integration and extensibility</a></li>
<li><a href="#orgdc2bc60">5.11. Tracing</a></li>
<li><a href="#orgc12fdf0">5.12. Bibliography</a></li>
</ul>
</li>
<li><a href="#org921feec">6. An EMF-like UML generator for C++</a>
<ul>
<li><a href="#org162bcfd">6.1. objectives</a></li>
<li><a href="#orgf86e87b">6.2. unification</a></li>
<li><a href="#orgf9b5d18">6.3. Java is the only first-class citizen of EMF</a></li>
<li><a href="#org9980595">6.4. Workflow</a></li>
<li><a href="#org97929e3">6.5. Annotations</a></li>
<li><a href="#org216d4b9">6.6. Two-generator approach</a></li>
<li><a href="#org6183535">6.7. Reflection</a></li>
<li><a href="#orga1baf76">6.8. UML OpaqueBehaviour</a></li>
<li><a href="#orgd053bcb">6.9. Memory management</a></li>
<li><a href="#org9487012">6.10. Benchmark</a></li>
<li><a href="#org836aa80">6.11. Bibliography</a></li>
</ul>
</li>
<li><a href="#org591c2b6">7. An Abstraction for Reusable MDD Components</a>
<ul>
<li><a href="#orgb2bb8c4">7.1. Gist of the approach</a></li>
<li><a href="#orgaba521b">7.2. Code patterns</a></li>
<li><a href="#orgcb70dea">7.3. QVT default merging strategy</a></li>
<li><a href="#org8f888d3">7.4. Building block</a></li>
<li><a href="#orgafbe6d0">7.5. Audit building block</a></li>
<li><a href="#org3ab320a">7.6. Issues with building blocks</a></li>
<li><a href="#org7fa00e6">7.7. Bibliography</a></li>
</ul>
</li>
<li><a href="#orgcf2eec6">8. Architecture-Centric Model-Driven Web Engineering</a>
<ul>
<li><a href="#org55824b1">8.1. AC-MDSD focuses on infrastructural code</a></li>
<li><a href="#orga74cbe7">8.2. Advantages of MDE for web apps</a></li>
<li><a href="#org0cf5855">8.3. Reference implementation driven approach</a></li>
<li><a href="#org766b043">8.4. White box and black box CASE tools</a></li>
<li><a href="#orged25322">8.5. Related work</a></li>
<li><a href="#orgf2dab26">8.6. Graphical vs Textual</a></li>
<li><a href="#orge022bf8">8.7. DDD Entity pattern and manager (service)</a></li>
<li><a href="#org1380f53">8.8. Two-track development approach</a></li>
<li><a href="#org0a17872">8.9. AC-MDSD approach with regards to extensibility</a></li>
<li><a href="#orge707e8e">8.10. Bibliography</a></li>
</ul>
</li>
<li><a href="#org0eb6ac2">9. A UML Profile for Feature Diagrams: Initiating a Model Driven Engineering Approach for Software Product Lines</a>
<ul>
<li><a href="#org04fb858">9.1. Objective is full lifecycle</a></li>
<li><a href="#orgf8673d8">9.2. Feature model elements</a></li>
<li><a href="#org281083e">9.3. Sub-features</a></li>
<li><a href="#orgb16de8e">9.4. UML Component as a feature</a></li>
<li><a href="#org6cc8fc5">9.5. Model-relationship</a></li>
<li><a href="#org133e178">9.6. Bibliography</a></li>
</ul>
</li>
<li><a href="#orge583ced">10. Generic Modeling using UML extensions for variability</a>
<ul>
<li><a href="#orgf511238">10.1. Feature models target end users</a></li>
<li><a href="#org43dcfe5">10.2. Instantiation of models into products</a></li>
<li><a href="#orgcaea277">10.3. Variation points</a></li>
<li><a href="#orga99a027">10.4. Generic models from Domain Engineering</a></li>
<li><a href="#org6f9825e">10.5. Hiding of less important information</a></li>
<li><a href="#orgd0cb071">10.6. Variation points</a></li>
<li><a href="#org485a1b2">10.7. Model evolution</a></li>
<li><a href="#orgc9d7412">10.8. Variation points and JSON</a></li>
<li><a href="#org25828b4">10.9. Binding times</a></li>
<li><a href="#org1bdedac">10.10. Variability at the model element level</a></li>
<li><a href="#org48b6881">10.11. Bibliography</a></li>
</ul>
</li>
<li><a href="#orgf2a85ba">11. Using Aspects to Model Product Line Variability</a>
<ul>
<li><a href="#orgb707bda">11.1. Product line engineering</a></li>
<li><a href="#orgb6277fe">11.2. MDSD and AOSD</a></li>
<li><a href="#orge0677c8">11.3. Domain Engineering / Application Engineering</a></li>
<li><a href="#orgded5de9">11.4. Model-level weaving</a></li>
<li><a href="#org032de65">11.5. Aspects for variability increases flexibility</a></li>
<li><a href="#org7089e94">11.6. Comparison between our approach and aspects</a></li>
</ul>
</li>
<li><a href="#org1d79f1b">12. A flexible code generator for MOF-based modeling languages</a>
<ul>
<li><a href="#org60fc56d">12.1. MOmoC</a></li>
<li><a href="#org183518c">12.2. Model compiler</a></li>
<li><a href="#orgf184bfa">12.3. MOmoC architecture</a></li>
</ul>
</li>
<li><a href="#orge6369a8">13. A Comparison of Generative Approaches: XVCL and GenVoca</a>
<ul>
<li><a href="#orge6d1c78">13.1. Compositional Design</a></li>
<li><a href="#org0bf3762">13.2. References</a></li>
</ul>
</li>
<li><a href="#org249633f">14. An evaluation of the Graphical Modeling Framework GMF based on the development of the CORAS tool</a>
<ul>
<li><a href="#orgb791770">14.1. Tagging in GMF</a></li>
<li><a href="#org14f462b">14.2. Packaging issues</a></li>
<li><a href="#org80df858">14.3. Avoid human interactions in generations</a></li>
</ul>
</li>
<li><a href="#orgad8d414">15. Features as transformations: A generative approach to software development</a>
<ul>
<li><a href="#org3242519">15.1. Feature selection</a></li>
<li><a href="#orgb511593">15.2. Feature interaction</a></li>
<li><a href="#orgbef6a51">15.3. Classification of transforms</a></li>
</ul>
</li>
<li><a href="#orgf3daf4f">16. Translating Alloy Specifications to UML Class Diagrams Annotated with OCL</a></li>
<li><a href="#orgd0d9885">17. Agile MDA</a></li>
<li><a href="#org43c929e">18. Model-driven Development of Complex Software: A Research Roadmap</a></li>
<li><a href="#org53e5e9e">19. A meta-model for language-independent refactoring</a></li>
<li><a href="#org3731310">20. Metrics on Feature Models to Optimise Configuration Adaptation at Runtime</a></li>
<li><a href="#org0d1d224">21. A UML profile for feature diagrams</a></li>
<li><a href="#orgb30eb43">22. AndroMDA</a></li>
<li><a href="#orgd1d12ee">23. Construction and Evolution of Code Generators</a></li>
<li><a href="#org3e46640">24. Bridging the Gap Between Features and Models</a></li>
<li><a href="#org5ba685c">25. Generating Aspect Code from UML Models</a></li>
<li><a href="#orgcc6372e">26. State of the art of QVT: a model transformation language standard</a></li>
<li><a href="#org2e957db">27. Generative Programming Using Frame Technology</a></li>
<li><a href="#org5c80c1a">28. Ecore.Fmp: A Tool For Editing And Instantiating Class Models As Feature Models</a></li>
<li><a href="#orge3e4326">29. Towards Separation of Concerns in Model Transformation Workflows</a></li>
<li><a href="#orgea94e0e">30. Classification of Model Transformation Approaches</a></li>
<li><a href="#org3673db9">31. Feature-Based Survey of Model Transformation Approaches</a></li>
<li><a href="#orgde1a2f8">32. Software Diversity: State of the Art and Perspectives</a></li>
<li><a href="#orgeb9a9c5">33. Variability in Software Architecture: Current Practices and Challenges</a></li>
<li><a href="#org3d685dc">34. Systems Variability Modeling: A Textual Model Mixing Class and Feature Concepts</a></li>
<li><a href="#org517da62">35. A Common Metamodel for Code Generation</a></li>
<li><a href="#orgb1293bd">36. A Code Generation Metamodel for ULF-Ware</a></li>
<li><a href="#org9c7046c">37. Aspect-Oriented Model-Driven Software Product Line Engineering</a>
<ul>
<li><a href="#orgdd7f25a">37.1. Expressing Variability in Structural Models</a></li>
<li><a href="#orgd39acba">37.2. Expressing Variability in Model Transformations</a></li>
<li><a href="#orgd9c4595">37.3. Expressing Variability in Code Generation Templates</a></li>
<li><a href="#orgc4b0db3">37.4. Expressing Variability in Code</a></li>
<li><a href="#org24e6bbd">37.5. Home Automation Case Study</a></li>
<li><a href="#orgc6036a3">37.6. Conclusions</a></li>
</ul>
</li>
<li><a href="#orgdc4f6cb">38. An Aspect-Oriented and Model-Driven Approach for Managing Dynamic Variability</a></li>
<li><a href="#org8ae7f29">39. A Feature Model for Model-to-Text Transformation Languages</a>
<ul>
<li><a href="#org3f4cc46">39.1. Abstract</a></li>
<li><a href="#org79c910a">39.2. Introduction</a></li>
<li><a href="#org297aa12">39.3. A Feature Model for M2T Languages</a></li>
</ul>
</li>
<li><a href="#org5f1a27b">40. Modeling Variability in Template-based Code Generators for Product Line Engineering</a>
<ul>
<li><a href="#orgf775cf6">40.1. Abstract</a></li>
<li><a href="#org3390b34">40.2. Introduction</a></li>
<li><a href="#org8576a0b">40.3. Variability Concepts in Code Generator Product Lines</a></li>
<li><a href="#orgec61f0f">40.4. Code Generator Variant Configuration and Generation</a></li>
<li><a href="#org5bd4da5">40.5. Demonstrating Example for Variability Regions</a></li>
<li><a href="#org752cdc6">40.6. Industrial Case Study</a></li>
<li><a href="#org1ed7d14">40.7. Related Work</a></li>
</ul>
</li>
</ul>
</div>
</div>
<p>
<a href="../index.html">Back to home page</a>.
</p>

<p>
Listing of papers I have read, and the notes I made. Most of the notes
use <a href="https://github.com/jkitchin/org-ref">org-ref</a> so that I can refer back to the page where they were made.
</p>

<div id="outline-container-orgc2cf5f4" class="outline-2">
<h2 id="orgc2cf5f4"><span class="section-number-2">1</span> Systems variability modeling : a textual model mixing class and feature concepts</h2>
<div class="outline-text-2" id="text-1">
<ul class="org-ul">
<li>Younis, Ola, Said Ghoul, and Mohammad H. Alomari.</li>
<li>"Systems variability modeling: a textual model mixing class and
feature concepts."</li>
<li><a href="https://arxiv.org/abs/1311.3243">arXiv preprint arXiv:1311.3243 (2013)</a>.</li>
</ul>
</div>

<div id="outline-container-org6278547" class="outline-3">
<h3 id="org6278547"><span class="section-number-3">1.1</span> Variability: separated approach</h3>
<div class="outline-text-3" id="text-1-1">
<p>
The approach of having variability separate from regular modeling is
called the "separated approach".
</p>
</div>
</div>

<div id="outline-container-org550a075" class="outline-3">
<h3 id="org550a075"><span class="section-number-3">1.2</span> Textual notation and mixing</h3>
<div class="outline-text-3" id="text-1-2">
<p>
Author claims that textual notations do not provide "integrated"
management of both modeling and variability, e.g. follow the separated
approach.
</p>

<p>
The opposite of the separate approach is "mixing", where we mix
classes and features.
</p>
</div>
</div>

<div id="outline-container-orge177345" class="outline-3">
<h3 id="orge177345"><span class="section-number-3">1.3</span> Features as conceptual elements</h3>
<div class="outline-text-3" id="text-1-3">
<p>
In the author's view features are conceptual elements whereas regular
modeling is physical. We take the view that regular modeling is a
conceptual concept and the physical layer lies in the realm of files
and directories.
</p>
</div>
</div>

<div id="outline-container-orgb2b58a6" class="outline-3">
<h3 id="orgb2b58a6"><span class="section-number-3">1.4</span> Product line steps</h3>
<div class="outline-text-3" id="text-1-4">
<p>
The idea that there are several steps in the the design and
implementation of a software product. The smaller the number of steps
the better. We should make clear what these steps are in MASD.
</p>
</div>
</div>

<div id="outline-container-orgd21fd3f" class="outline-3">
<h3 id="orgd21fd3f"><span class="section-number-3">1.5</span> Core assets</h3>
<div class="outline-text-3" id="text-1-5">
<p>
From a MASD perspective, the catalog of schematic and repetitive
patterns is the set of reusable core assets, not the meta-model
elements. We need to make this clear in the conceptual model.
</p>
</div>
</div>

<div id="outline-container-org9db32ad" class="outline-3">
<h3 id="org9db32ad"><span class="section-number-3">1.6</span> Feature model use in MASD</h3>
<div class="outline-text-3" id="text-1-6">
<p>
Unlike regular MDE approaches, in MASD we do not allow users to create
their own feature models for their particular problem domain (what the
author calls the domain space). Instead, users can make <i>selections</i>
over the MASD feature model, defining what features are required for
the product in question. However, users cannot redefine the feature
model, only instantiate it.
</p>

<p>
We should make sure we explain that there are two different views on
variability, depending on whether we are Dogen Developers or Dogen
Users.
</p>
</div>
</div>

<div id="outline-container-org6022585" class="outline-3">
<h3 id="org6022585"><span class="section-number-3">1.7</span> Mixing</h3>
<div class="outline-text-3" id="text-1-7">
<p>
Author seems to claim that having a feature model and a class model
separately, and subsequently mixing the two to obtain the SPL product
is still part of the mixed approach. There are several techniques to
perform the mixing:
</p>

<ul class="org-ul">
<li>constraint additions</li>
<li>relation definition</li>
<li>reference links</li>
</ul>
</div>
</div>

<div id="outline-container-orgb99e7f9" class="outline-3">
<h3 id="orgb99e7f9"><span class="section-number-3">1.8</span> Feature selection</h3>
<div class="outline-text-3" id="text-1-8">
<p>
The process of feature selection involves resolving constraints
amongst features. Interesting term "fixed features". This seems to
describe the MASD approach well.
</p>
</div>
</div>

<div id="outline-container-orgf2d2c4d" class="outline-3">
<h3 id="orgf2d2c4d"><span class="section-number-3">1.9</span> Complexity in configurations step</h3>
<div class="outline-text-3" id="text-1-9">
<p>
In proper SPL products that make use of feature models, the mixing of
feature models and class diagrams creates a lot of complexity. In
particular, the selection of features and its impact on the class
models is very important. If the process for mixing is too complex,
users will not be able to make use of this approach. MASD takes a very
simplistic view, defining a very simple feature model in order to
tackle this problem.
</p>
</div>
</div>

<div id="outline-container-org5a305c8" class="outline-3">
<h3 id="org5a305c8"><span class="section-number-3">1.10</span> Bridge between product line design and OO</h3>
<div class="outline-text-3" id="text-1-10">
<p>
MASD provides a bridge between these two distinct worlds, but the
bridge is very narrow in order to keep the complexity down. The MASD
model has a small number of concepts:
</p>

<div class="epigraph"><blockquote>
<p>
Provide a new concise and rich textual notation for feature modeling
and class modeling. It allows simple and natural new way of mixing
feature models and class models using small number of concepts.
</p>

</blockquote></div>

<p>
Requirements for a solution:
</p>

<ul class="org-ul">
<li>the mixing solution should be both concise and rich.</li>
<li>simple, coherent, and complete configuration generation</li>
</ul>
</div>
</div>

<div id="outline-container-org3da7625" class="outline-3">
<h3 id="org3da7625"><span class="section-number-3">1.11</span> CLAFER mixing</h3>
<div class="outline-text-3" id="text-1-11">
<p>
The approach used by CLAFER for their mixing is interesting. It is
based on constraints and inheritance. The FM is a collection of type
definitions and features and it is joined with the class model as
attributes and attribute values. We need to read up on CLAFER.
</p>
</div>
</div>

<div id="outline-container-orgfc6194d" class="outline-3">
<h3 id="orgfc6194d"><span class="section-number-3">1.12</span> OOFM: Sarinho and Apolonario</h3>
<div class="outline-text-3" id="text-1-12">
<p>
Interesting paper to read: V. T. Sarinho and A. L. Apolinario (2010),
“Combining feature modeling and Object Oriented concepts to manage the
software variability”, IEEE International Conference on Information
Reuse and Integration (IRI), pp. 344-349.
</p>
</div>
</div>

<div id="outline-container-org7fe40c5" class="outline-3">
<h3 id="org7fe40c5"><span class="section-number-3">1.13</span> ECORE feature model</h3>
<div class="outline-text-3" id="text-1-13">
<p>
M. Stephan and M. Antkiewicz (2008), “Ecore.fmp: A tool for editing
and instantiating class models as feature models”, University of
Waterloo, Waterloo, Technical Report.
</p>
</div>
</div>

<div id="outline-container-orgd218188" class="outline-3">
<h3 id="orgd218188"><span class="section-number-3">1.14</span> Implementation models</h3>
<div class="outline-text-3" id="text-1-14">
<p>
MASD focuses solely on implementation models.
</p>
</div>
</div>

<div id="outline-container-org1fdd6c7" class="outline-3">
<h3 id="org1fdd6c7"><span class="section-number-3">1.15</span> Conceptual model components</h3>
<div class="outline-text-3" id="text-1-15">
<ul class="org-ul">
<li>feature concepts;</li>
<li>object-oriented concepts;</li>
<li>rules for mixing classes and features.</li>
</ul>
</div>
</div>

<div id="outline-container-org4484dc4" class="outline-3">
<h3 id="org4484dc4"><span class="section-number-3">1.16</span> TDM components</h3>
<div class="outline-text-3" id="text-1-16">
<p>
Composed of four feature modules:
</p>

<ul class="org-ul">
<li>Features types: "This feature module captures all features in the
system with their possible values. It is composed by Features<sub>Types</sub>
and Relation<sub>Types</sub>."</li>
<li>Features Global: "This feature module specifies the Global features
that will be shared between all system components."</li>
<li>Features Control: "This feature module is composed by relations only,
and its main goal is to keep systems’ components stable and avoid
any conflicts."</li>
<li>Features Configuration: "This feature module is composed by
relations only, and its main goal is to keep systems’ components
stable and avoid any conflicts."</li>
</ul>
</div>
</div>

<div id="outline-container-org41d0fa9" class="outline-3">
<h3 id="org41d0fa9"><span class="section-number-3">1.17</span> Meta-Features Model</h3>
<div class="outline-text-3" id="text-1-17">
<p>
Models all features in TDM, template for feaures in the Features
Meta-Model. Seems like a Meta-Meta-Model.
</p>
</div>
</div>

<div id="outline-container-org9fd5843" class="outline-3">
<h3 id="org9fd5843"><span class="section-number-3">1.18</span> Features Meta-Model</h3>
<div class="outline-text-3" id="text-1-18">
<p>
Based on the MFM. "This is an intermediate model between the
conceptual part (Feature Meta-Model) and the physical part (Product
Model).
</p>
</div>
</div>

<div id="outline-container-org14df180" class="outline-3">
<h3 id="org14df180"><span class="section-number-3">1.19</span> Application Areas</h3>
<div class="outline-text-3" id="text-1-19">
<p>
Provide a list of specific use cases that can benefit from MASD with
examples.
</p>
</div>
</div>

<div id="outline-container-orgb322fcc" class="outline-3">
<h3 id="orgb322fcc"><span class="section-number-3">1.20</span> TDM has strong typing</h3>
<div class="outline-text-3" id="text-1-20">
<p>
The TDM approach of having strong types for features is similar to our
approach in that the features meta-model defines the domain of
instantiation for all types used in configuration.
</p>
</div>
</div>

<div id="outline-container-org354ed57" class="outline-3">
<h3 id="org354ed57"><span class="section-number-3">1.21</span> TDM methodology</h3>
<div class="outline-text-3" id="text-1-21">
<p>
TDM uses feature modeling as part of a wider methodology, guiding its
use. Similarly with MASD, feature modeling is fixed by the methodology
itself, and therefore integrated in the modeling approach.
</p>
</div>
</div>

<div id="outline-container-orgf174f3c" class="outline-3">
<h3 id="orgf174f3c"><span class="section-number-3">1.22</span> Conclusions</h3>
<div class="outline-text-3" id="text-1-22">
<p>
Steps:
</p>

<ul class="org-ul">
<li>from a feature meta-model, we instantiate it by creating features.</li>
<li></li>


<li>features may be of different types. In our case we seem to have
control features (enablement)</li>
</ul>


<p>
Notes:
</p>

<ul class="org-ul">
<li>instead of their notion of global features (shared between system
components) we have features with different binding points: global,
element, etc.</li>
<li>we do have a notion of "feature types": we have features that are
just "input parameters" with values that are read out and used;
other features such as enablement, produce wider changes.</li>
<li>we need to explain how our mixing approach fits in with existing
mixing approaches. Is there a survey of mixing? We need to define a
methodology for the mixing process.</li>
<li>the logical model is an OO model. The physical model defines a
meta-model for the implementation. The variability model defines a
feature meta-model and model. The product models are instances of
all of these models.</li>
<li>we use features for the solution space.</li>
<li>for us "variant products" has a different meaning. Since we only
care about SRAPs, to call a MASD product a variant is not very
meaningful. However, users define families and those have products
as instances.</li>
<li>we don't yet solve constraints amongst features. OR: we take an
empirical approach to features: general statements are hard and
inflexible so we check for correctness on a case by case basis. This
is our trade-off.</li>
<li>our approach is to create a code generation meta-model which exposes
the smallest amount of MDE concepts to the end user. The end user is
free to exploit them via existing tooling such as EMF. Our code
generator is a bridge between regular development and MDE.</li>
<li>feature models typically focus on problem space. We use them for the
solution space.</li>
<li>major disagreement with author: we do not believe text notation is
better or worse than graphical notation; they have different
properties and therefore different uses. We'd like to support both.</li>
<li>taxonomy of features: static, dynamic (feature toggles). For dynamic
features we need a separate library. Actually, could we use a
library that handles both? Maybe its just a coincidence that the
code generator supports its features directly from a model. The
difference is in the model we have context (global and local
features).</li>
</ul>

<p>
Summary:
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Aspect</th>
<th scope="col" class="org-left">TDM Approach</th>
<th scope="col" class="org-left">MASD Approach</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Meta-Features model</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">Hard-coded.</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>

<div id="outline-container-orga7bfa29" class="outline-2">
<h2 id="orga7bfa29"><span class="section-number-2">2</span> A Code Generation Metamodel for ULF-Ware Generating Code for SDL and Interfacing with the Runtime Library</h2>
<div class="outline-text-2" id="text-2">
</div>

<div id="outline-container-orgbafcd5e" class="outline-3">
<h3 id="orgbafcd5e"><span class="section-number-3">2.1</span> Intermediate model</h3>
<div class="outline-text-3" id="text-2-1">
<p>
Instead of creating a meta-model that is general and useful for many
use cases, its best to create a meta-model specific for code
generation only.
</p>
</div>
</div>

<div id="outline-container-org30ad9a8" class="outline-3">
<h3 id="org30ad9a8"><span class="section-number-3">2.2</span> Generality and Behaviour</h3>
<div class="outline-text-3" id="text-2-2">
<p>
Authors believe that the model should be general in order to support
several target languages, which we agree with, but they also think
behaviour is important - which we disagree.
</p>
</div>
</div>

<div id="outline-container-org5697f97" class="outline-3">
<h3 id="org5697f97"><span class="section-number-3">2.3</span> Need for behaviour</h3>
<div class="outline-text-3" id="text-2-3">
<p>
Authors claim that a structural-only model is not sufficient, but do
not provide additional justification for their views.
</p>
</div>
</div>

<div id="outline-container-orgae42e86" class="outline-3">
<h3 id="orgae42e86"><span class="section-number-3">2.4</span> Decreasing complexity by shared meta-model</h3>
<div class="outline-text-3" id="text-2-4">
<p>
Not clear why authors think we need n * m libraries. But at any rate,
with a shared infrastructure we can manage to significantly reduce
code duplication. We still need language specific PDMs.
</p>
</div>
</div>

<div id="outline-container-org1f56ac2" class="outline-3">
<h3 id="org1f56ac2"><span class="section-number-3">2.5</span> MOF</h3>
<div class="outline-text-3" id="text-2-5">
<p>
The use of a standard meta-meta-model provides a lot of tooling
infrastructure and simplifies the work. We need to justify why we did
not build upon this approach.
</p>
</div>
</div>

<div id="outline-container-org17e90fa" class="outline-3">
<h3 id="org17e90fa"><span class="section-number-3">2.6</span> Difficulties in generation</h3>
<div class="outline-text-3" id="text-2-6">
<p>
Authors explain the difficulty of code generation from abstract
models. We should mention our solution to this problem, which is to
capture schematic and repetitive patterns found in code.
</p>
</div>
</div>

<div id="outline-container-orgdc7b658" class="outline-3">
<h3 id="orgdc7b658"><span class="section-number-3">2.7</span> Model abstraction level is key</h3>
<div class="outline-text-3" id="text-2-7">
<p>
Finding the right level of abstraction at which to model is very
important. If a model is too close to source code it is very difficult
to handle in terms of transformations, if it is too far away from
source code, the code generation is very hard.
</p>
</div>
</div>

<div id="outline-container-org1d09ca5" class="outline-3">
<h3 id="org1d09ca5"><span class="section-number-3">2.8</span> Commonalities for OO</h3>
<div class="outline-text-3" id="text-2-8">
<p>
Authors make a case for a common model for several OO languages for
code generation.
</p>
</div>
</div>

<div id="outline-container-org088ef1f" class="outline-3">
<h3 id="org088ef1f"><span class="section-number-3">2.9</span> Multi-language and common denominators</h3>
<div class="outline-text-3" id="text-2-9">
<p>
By supporting multiple languages, the authors decided that only
features that are common to all languages are supported in the
meta-model. Our approach is to have some features supported on some
languages but not others.
</p>
</div>
</div>

<div id="outline-container-org1c29c65" class="outline-3">
<h3 id="org1c29c65"><span class="section-number-3">2.10</span> Low-level approach</h3>
<div class="outline-text-3" id="text-2-10">
<p>
Authors seem to be concerned with low-level language details at code
generation level. We believe instead that much of the massaging
required can be done at the M2T transformation level, and the role of
the PDMs is only when large missing features need to be provided.
</p>
</div>
</div>

<div id="outline-container-orgf8cfac7" class="outline-3">
<h3 id="orgf8cfac7"><span class="section-number-3">2.11</span> Too much detail</h3>
<div class="outline-text-3" id="text-2-11">
<p>
    As with the right level of modeling, the right level of detail on the
code generator is also an engineering trade off. We decided to add
more detail to the generation in order to keep the meta-model simpler.
</p>

<p>
Creating a library to make the different OO languages look the same
has a lot of disadvantages:
</p>

<ul class="org-ul">
<li>a lot of code to maintain.</li>
<li>non-idiomatic code that developers of that language will not
understand.</li>
</ul>
</div>
</div>

<div id="outline-container-org1de1da6" class="outline-3">
<h3 id="org1de1da6"><span class="section-number-3">2.12</span> UML Infrastructure</h3>
<div class="outline-text-3" id="text-2-12">
<p>
Whilst the authors claim their meta-model is designed for
code-generation, it seems its more concerned with UML compatibility
rather than a close fit to the the requirements of the generator. We
take the exact opposite approach: our model is designed specifically
to fit the code generation requirements.
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">CeeJay type</th>
<th scope="col" class="org-left">Dogen Type</th>
<th scope="col" class="org-left">Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Package</td>
<td class="org-left">Module</td>
<td class="org-left">Low-level mapping, forcing all of C++ elements to be declared in the same header.</td>
</tr>

<tr>
<td class="org-left">Class</td>
<td class="org-left">Object</td>
<td class="org-left">No multiple inheritance.</td>
</tr>

<tr>
<td class="org-left">Types</td>
<td class="org-left">N/A</td>
<td class="org-left">We use multiple meta-model types for this concept.</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-org289b59c" class="outline-3">
<h3 id="org289b59c"><span class="section-number-3">2.13</span> Handling of primitives</h3>
<div class="outline-text-3" id="text-2-13">
<p>
CeeJay expects the existence of a number of "core" types. This is not
enforced formally. Dogen sees these as plain model types, defined in
PDMs. Builtins are no different from any model type.
</p>
</div>
</div>

<div id="outline-container-orga837c6b" class="outline-3">
<h3 id="orga837c6b"><span class="section-number-3">2.14</span> Uniform interfaces to collections</h3>
<div class="outline-text-3" id="text-2-14">
<p>
CeeJay's approach of having uniform interfaces to collections is not
ideal because we either duplicate the existing standard libraries into
a "CeeJay standard library", which is not idiomatic, not well
maintained, etc - or worse, we create a small number of simple
collections which do not have the required expressive power of a full
standard library.
</p>
</div>
</div>

<div id="outline-container-orgffea59a" class="outline-3">
<h3 id="orgffea59a"><span class="section-number-3">2.15</span> Function modeling</h3>
<div class="outline-text-3" id="text-2-15">
<p>
It is very difficult to model functions (behaviour in
general). Authors point out challenges. We avoid this problem by not
modeling operations other than for the purposes of merging code
generation, which will be added later on.
</p>
</div>
</div>

<div id="outline-container-org294ade7" class="outline-3">
<h3 id="org294ade7"><span class="section-number-3">2.16</span> Predefined issues</h3>
<div class="outline-text-3" id="text-2-16">
<p>
By relying on MOF, we start to pull in runtime dependencies to the
modeling environment, meaning all users of the generated code are now
exposed to the modeling implementation.
</p>
</div>
</div>

<div id="outline-container-org6882381" class="outline-3">
<h3 id="org6882381"><span class="section-number-3">2.17</span> References</h3>
<div class="outline-text-3" id="text-2-17">
<p>
Papers to read:
</p>

<p>
Piefel, M.: A common metamodel for code generation. In: J. Aguilar (ed.), Pro-
ceedings of the 3rd International Conference on Cybernetics and Information Tech-
nologies, Systems and Applications. I I I S, Orlando, USA (2006)
</p>
</div>
</div>
</div>

<div id="outline-container-org35cdb64" class="outline-2">
<h2 id="org35cdb64"><span class="section-number-2">3</span> A Lightweight MDSD Process Applied in Small Projects</h2>
<div class="outline-text-2" id="text-3">
</div>

<div id="outline-container-org7d050c4" class="outline-3">
<h3 id="org7d050c4"><span class="section-number-3">3.1</span> Important success factors</h3>
<div class="outline-text-3" id="text-3-1">
<ul class="org-ul">
<li>"Its learning curve"</li>
<li>"its adaptability to special requirements"</li>
<li>"the maturity of the supporting tools"</li>
</ul>
</div>
</div>

<div id="outline-container-orgddca790" class="outline-3">
<h3 id="orgddca790"><span class="section-number-3">3.2</span> Range of tooling in MDE is vast</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Its never quite clear how one decides if a tool is part of MDE or not.
</p>
</div>
</div>

<div id="outline-container-org2a2ee1e" class="outline-3">
<h3 id="org2a2ee1e"><span class="section-number-3">3.3</span> pragmatic approach</h3>
<div class="outline-text-3" id="text-3-3">
<p>
Similar to MDSD, the authors decided to take on a pragmatic approach
with the following key factors:
</p>

<ul class="org-ul">
<li>partial usage</li>
<li>create a tool rather than use an existing one due to cost factors;
the include open source tools as well.</li>
<li>iterative approach to building the tool.</li>
</ul>
</div>
</div>

<div id="outline-container-orge8219a6" class="outline-3">
<h3 id="orge8219a6"><span class="section-number-3">3.4</span> Target is small projects</h3>
<div class="outline-text-3" id="text-3-4">
<p>
Similar to MASD, the target of this paper is the small and middle size
projects with limited resourcing.
</p>
</div>
</div>

<div id="outline-container-orgc0d27af" class="outline-3">
<h3 id="orgc0d27af"><span class="section-number-3">3.5</span> Requirments</h3>
<div class="outline-text-3" id="text-3-5">
<p>
The requirements for this project are actually quite general:
</p>

<ul class="org-ul">
<li>risk mitigation by allowing the use of traditional development if
MDE is found to be problematic.</li>
<li>no extra time allowed to develop MDE tools.</li>
<li>cost is an important factor and training is limited.</li>
<li>code should be human readable and modifiable.</li>
</ul>
</div>
</div>

<div id="outline-container-orgc2a9dc0" class="outline-3">
<h3 id="orgc2a9dc0"><span class="section-number-3">3.6</span> Activities</h3>
<div class="outline-text-3" id="text-3-6">
<p>
The approach is a traditional dual-track development model, with a
separation of the MDE team from the main team, and using integration
points to join the work. MASD is very different in that we intend to
back out the MDE parts of the work by empirical analysis of existing
code.
</p>
</div>
</div>

<div id="outline-container-org945de10" class="outline-3">
<h3 id="org945de10"><span class="section-number-3">3.7</span> MDE develppment process</h3>
<div class="outline-text-3" id="text-3-7">
<p>
Crucially, the MDE development process is driven by the MDE team. They
work off of prototypes they develop and then deliver features to the
agile team which provides feedback. The problem with this approach is
that the features do not need to be grounded on the needs of the agile
team and can be speculative.
</p>
</div>
</div>

<div id="outline-container-org0511255" class="outline-3">
<h3 id="org0511255"><span class="section-number-3">3.8</span> Template development</h3>
<div class="outline-text-3" id="text-3-8">
<p>
It is positive that templates are attempting to recreate code that was
manually crafted, as this is a very good sanity check.
</p>
</div>
</div>

<div id="outline-container-orgbafe66c" class="outline-3">
<h3 id="orgbafe66c"><span class="section-number-3">3.9</span> Bibliography</h3>
<div class="outline-text-3" id="text-3-9">
<ul class="org-ul">
<li>“Code Generation Information for the Pragmatic Engineer,” <a href="http://www.codegeneration.net/">http://www.codegeneration.net/</a>.</li>
<li>V. Kulkarni and S. Reddy, “Introducing MDA in a Large IT Consultancy
Organization,” in APSEC. IEEE Computer Society, 2006, pp. 419–426.</li>
<li>G. Guta, B. Szasz, and W. Schreiner, “A Lightweight Model Driven Development Process based on XML Technology,”</li>
</ul>
<p>
RISC Report Series, University of Linz, Austria, Tech. Rep. 08-01, March 2008.
</p>
</div>
</div>
</div>

<div id="outline-container-orgedbd937" class="outline-2">
<h2 id="orgedbd937"><span class="section-number-2">4</span> Proceso de Desarrollo de Software Mediante Herramientas MDA</h2>
<div class="outline-text-2" id="text-4">
<p>
Link: <a href="http://www.iiisci.org/journal/CV$/risci/pdfs/C476AI.pdf">http://www.iiisci.org/journal/CV$/risci/pdfs/C476AI.pdf</a>
</p>
</div>
</div>

<div id="outline-container-org50f1446" class="outline-2">
<h2 id="org50f1446"><span class="section-number-2">5</span> Un estudio comparativo de dos herramientas MDA: OptimalJ y ArcStyler</h2>
<div class="outline-text-2" id="text-5">
<p>
Link: <a href="http://dis.um.es/~mjortin/articulos/tdsdm04.pdf">http://dis.um.es/~mjortin/articulos/tdsdm04.pdf</a>
</p>

<p>
Words that are not clear:
</p>

<ul class="org-ul">
<li>trazabilidad</li>
<li>marcas: tagging?</li>
</ul>
</div>

<div id="outline-container-org58a6923" class="outline-3">
<h3 id="org58a6923"><span class="section-number-3">5.1</span> Important factors</h3>
<div class="outline-text-3" id="text-5-1">
<ul class="org-ul">
<li>PIM annotations</li>
<li>whether the PSM is implicit or explicit.</li>
</ul>
</div>
</div>

<div id="outline-container-org32fce9c" class="outline-3">
<h3 id="org32fce9c"><span class="section-number-3">5.2</span> MDA principles</h3>
<div class="outline-text-3" id="text-5-2">
<ul class="org-ul">
<li>split the specification of the functionality of a software system
from the implementation.</li>
</ul>
</div>
</div>

<div id="outline-container-orgb7a182a" class="outline-3">
<h3 id="orgb7a182a"><span class="section-number-3">5.3</span> Model compiler</h3>
<div class="outline-text-3" id="text-5-3">
<p>
MDA focuses on the creation of "model compilers" but we have not yet
found a formal definition of what one is. It is clearly related to the
transformations from CIM, PIM, PSM etc.
</p>
</div>
</div>

<div id="outline-container-org8233a65" class="outline-3">
<h3 id="org8233a65"><span class="section-number-3">5.4</span> Evaluation properties</h3>
<div class="outline-text-3" id="text-5-4">
<p>
Properties that are evaluated for each tool. We should evaluate Dogen
against these as well. Measured as 0 to 4: nulo, mínimo, medio, bueno,
excelente
</p>

<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Id</th>
<th scope="col" class="org-left">Property</th>
<th scope="col" class="org-left">Comment</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">P01</td>
<td class="org-left">PIM support</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P02</td>
<td class="org-left">PSM support</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P03</td>
<td class="org-left">Multiple implementations.</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P04</td>
<td class="org-left">Model integration</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P05</td>
<td class="org-left">Interoperability</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P06</td>
<td class="org-left">Transformation definition</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P07</td>
<td class="org-left">Model verification</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P08</td>
<td class="org-left">Use of patterns (GoF)</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P10</td>
<td class="org-left">Support for incremental consistency</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P11</td>
<td class="org-left">Support for model transforms</td>
<td class="org-left">PIM-PSM, PSM-PSM, etc.</td>
</tr>

<tr>
<td class="org-left">P12</td>
<td class="org-left">Tracing</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P13</td>
<td class="org-left">Development lifecycle support</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P14</td>
<td class="org-left">Use of standards</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P15</td>
<td class="org-left">Control and refinement of transforms</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P16</td>
<td class="org-left">Quality of generated code</td>
<td class="org-left">&#xa0;</td>
</tr>

<tr>
<td class="org-left">P17</td>
<td class="org-left">Support tools</td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgc786bc3" class="outline-3">
<h3 id="orgc786bc3"><span class="section-number-3">5.5</span> OptimalJ: Three types of models</h3>
<div class="outline-text-3" id="text-5-5">
<ul class="org-ul">
<li>Domain model: high-level PIM (CIM?)</li>
<li>Application model: PSM aspects such as J2EE implementation.</li>
<li>Code model: generated from the application model.</li>
</ul>
</div>
</div>

<div id="outline-container-org1f2290b" class="outline-3">
<h3 id="org1f2290b"><span class="section-number-3">5.6</span> OptimalJ: Pattern types</h3>
<div class="outline-text-3" id="text-5-6">
<ul class="org-ul">
<li>Transformation patterns: patterns between models, transforming PIM
to PSM, PSM to code, etc.</li>
<li>Functional patterns: typical GoF patterns.</li>
</ul>
</div>
</div>

<div id="outline-container-orgdcf086d" class="outline-3">
<h3 id="orgdcf086d"><span class="section-number-3">5.7</span> OptimalJ: Protected regions</h3>
<div class="outline-text-3" id="text-5-7">
<p>
Due to "open regions" and "protected regions", OJ is able to keep code
that was manually crafted between generations.
</p>
</div>
</div>

<div id="outline-container-orgd85c4cb" class="outline-3">
<h3 id="orgd85c4cb"><span class="section-number-3">5.8</span> ArcStyler: Cartridges</h3>
<div class="outline-text-3" id="text-5-8">
<p>
According to the authors, this tool has a very advanced system for the
management of cartridges:
</p>

<ul class="org-ul">
<li>they use UML profiles for the integration of cartridges with the
modeling (for example, it defines a UML profile that exposes the EJB
or Java 2 PSM functionality).</li>
<li>there is a cartridge management system that handles them like
plugins.</li>
<li>its possible to define new cartridges from existing ones.</li>
</ul>

<p>
Info on the CARAT architecture can be found here:
</p>

<ul class="org-ul">
<li><a href="http://dis.um.es/~jmolina/documentos/CartuchosMDA.pdf">http://dis.um.es/~jmolina/documentos/CartuchosMDA.pdf</a></li>
</ul>
</div>
</div>

<div id="outline-container-orged840af" class="outline-3">
<h3 id="orged840af"><span class="section-number-3">5.9</span> Focus on design patterns</h3>
<div class="outline-text-3" id="text-5-9">
<p>
Authors seem to imply that the extensive use of design patterns is
sufficient to determine the quality of the generated code. We disagree
with this opinion.
</p>
</div>
</div>

<div id="outline-container-orgb4ccef8" class="outline-3">
<h3 id="orgb4ccef8"><span class="section-number-3">5.10</span> Tradeoffs between integration and extensibility</h3>
<div class="outline-text-3" id="text-5-10">
<p>
The two applications take very different approaches. OptimalJ focuses
its support mainly on J2EE and EJB. This allows it to provide
routripping and deep integration between PIM and PSM, and generate a
complete functional product. However, the company tightly controls the
product and users cannot extend it at will. On the other hand,
ArcStyle is openly extensible, but the downside is that cartridges
are responsible for making sure they interoperate. This means that
sometimes things don't work well with each other.
</p>
</div>
</div>

<div id="outline-container-orgdc2bc60" class="outline-3">
<h3 id="orgdc2bc60"><span class="section-number-3">5.11</span> Tracing</h3>
<div class="outline-text-3" id="text-5-11">
<p>
It is very important to trace all elements such that one can tell what
model elements generated which files. Our tracing at present is mostly
concerned with obtaining model state before and after transforms and
is not designed for end users. However, a report detailing who
generated what would be extremely helpful.
</p>
</div>
</div>

<div id="outline-container-orgc12fdf0" class="outline-3">
<h3 id="orgc12fdf0"><span class="section-number-3">5.12</span> Bibliography</h3>
<div class="outline-text-3" id="text-5-12">
<ul class="org-ul">
<li>MDA Guide Version 1.0.1. OMG. 2003.: More on model instance mapping
and model type mapping in the</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org921feec" class="outline-2">
<h2 id="org921feec"><span class="section-number-2">6</span> An EMF-like UML generator for C++</h2>
<div class="outline-text-2" id="text-6">
<p>
Link: <a href="https://www.scitepress.org/Papers/2016/57448/57448.pdf">https://www.scitepress.org/Papers/2016/57448/57448.pdf</a>
</p>
</div>

<div id="outline-container-org162bcfd" class="outline-3">
<h3 id="org162bcfd"><span class="section-number-3">6.1</span> objectives</h3>
<div class="outline-text-3" id="text-6-1">
<ul class="org-ul">
<li>targets legacy systems that have been written in c++ and therefore
can't easily make use of EMF.</li>
</ul>
</div>
</div>

<div id="outline-container-orgf86e87b" class="outline-3">
<h3 id="orgf86e87b"><span class="section-number-3">6.2</span> unification</h3>
<div class="outline-text-3" id="text-6-2">
<p>
One of OMGs goals is to unify every step of the development process,
from requirements gathering to deployment. We should make it clear
which parts of the development process we are aiming to automate.
</p>
</div>
</div>

<div id="outline-container-orgf9b5d18" class="outline-3">
<h3 id="orgf9b5d18"><span class="section-number-3">6.3</span> Java is the only first-class citizen of EMF</h3>
<div class="outline-text-3" id="text-6-3">
<p>
EMF is great for those in Java but it does not aim to provide support
outside of this environment.
</p>
</div>
</div>

<div id="outline-container-org9980595" class="outline-3">
<h3 id="org9980595"><span class="section-number-3">6.4</span> Workflow</h3>
<div class="outline-text-3" id="text-6-4">
<p>
From a Dogen perspective, UML4CPP is just another PDM (platform
definition model) and we could target it. It would allow us to
generate "MDE compliant" code, useful for certain scenarios. For this
we probably also need a UML4CPP/ecore specific facet which is
responsible for bridging the Dogen meta-model elements into
ecore. Actually this is probably not a good idea because to bridge the
gap between the two different representations we would end up creating
a lot of brittle glue code. We should just have two completely
different kernels - the regular MASD kernel and an EMF kernel.
</p>

<p>
This approach is useful in two ways:
</p>

<ul class="org-ul">
<li>to create an EMF injector. For this we could use the eCore code to
parse EMF models and then adapt these into dogen as we do with any
other injector type. The generated code will look like regular dogen
code, and it will make use of the MASD kernel. This is just using
eCore as a bridge into Dogen.</li>
<li>the second approach is to have a EMF/eCore kernel which generates
code which has the full functionality of eCore including
run-time/dynamic aspects. For this we rely on UML4CPP as a PDM.</li>
</ul>
</div>
</div>

<div id="outline-container-org97929e3" class="outline-3">
<h3 id="org97929e3"><span class="section-number-3">6.5</span> Annotations</h3>
<div class="outline-text-3" id="text-6-5">
<p>
eCore models are augmented via annotations. We need to understand how
these differ from our variability approach and make sure our names are
in line with the EMF annotation terminology.
</p>
</div>
</div>

<div id="outline-container-org216d4b9" class="outline-3">
<h3 id="org216d4b9"><span class="section-number-3">6.6</span> Two-generator approach</h3>
<div class="outline-text-3" id="text-6-6">
<p>
Instead of having a single generator for both eCore and user models,
there is one eCore generator and another just for user models.
</p>
</div>
</div>

<div id="outline-container-org6183535" class="outline-3">
<h3 id="org6183535"><span class="section-number-3">6.7</span> Reflection</h3>
<div class="outline-text-3" id="text-6-7">
<p>
Use of reflection at run time is seen as an essential property of the
approach. In contrast in MASD we aim to avoid using reflection as much
as possible.
</p>
</div>
</div>

<div id="outline-container-orga1baf76" class="outline-3">
<h3 id="orga1baf76"><span class="section-number-3">6.8</span> UML OpaqueBehaviour</h3>
<div class="outline-text-3" id="text-6-8">
<p>
Investigate this term.
</p>
</div>
</div>

<div id="outline-container-orgd053bcb" class="outline-3">
<h3 id="orgd053bcb"><span class="section-number-3">6.9</span> Memory management</h3>
<div class="outline-text-3" id="text-6-9">
<p>
Because the UML4CPP framework knows how the model is structured, it
can generate efficient memory management code. This means using raw
pointers is possible in a safe manner. In Dogen we have a similar
knowledge of the user code. We could also take advantage of this by
introducing some kind of "model level pointer" class which results in
generating appropriate memory management code.
</p>
</div>
</div>

<div id="outline-container-org9487012" class="outline-3">
<h3 id="org9487012"><span class="section-number-3">6.10</span> Benchmark</h3>
<div class="outline-text-3" id="text-6-10">
<p>
We could implement the test model in Dogen and perform similar
benchmarks to compare the performance of an EMF based kernel versus a
MASD based kernel in Dogen.
</p>
</div>
</div>

<div id="outline-container-org836aa80" class="outline-3">
<h3 id="org836aa80"><span class="section-number-3">6.11</span> Bibliography</h3>
<div class="outline-text-3" id="text-6-11">
<p>
Interesting papers:
</p>

<ul class="org-ul">
<li>Jungebloud, T., Jager, S., Maschotta, R., and Zimmermann,
A. (2013). MOF Compliant Fundamentals for Multi-Domain System
Modeling and Simulation. In Systems Conference (SysCon), 2013 IEEE
International, pages 191–194. IEEE.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org591c2b6" class="outline-2">
<h2 id="org591c2b6"><span class="section-number-2">7</span> An Abstraction for Reusable MDD Components</h2>
<div class="outline-text-2" id="text-7">
<p>
Link: <a href="https://dl.acm.org/doi/pdf/10.1145/1449913.1449940">https://dl.acm.org/doi/pdf/10.1145/1449913.1449940</a>
</p>

<p>
Kulkarni, Vinay, and Sreedhar Reddy. "An abstraction for reusable MDD
components: model-based generation of model-based code generators."
Proceedings of the 7th international conference on Generative
programming and component engineering. 2008.
</p>
</div>


<div id="outline-container-orgb2bb8c4" class="outline-3">
<h3 id="orgb2bb8c4"><span class="section-number-3">7.1</span> Gist of the approach</h3>
<div class="outline-text-3" id="text-7-1">
<p>
The paper describes a method for generation of code generators as a
hierarchical composition of reusable building blocks. A building
block is a localised specification; this is similar to our concept of
a physical space.
</p>

<p>
Authors propose a three step approach:
</p>

<ol class="org-ol">
<li>transform individual concern specific models into a unified model.</li>
<li>transform unified model into concern specific text artefacts</li>
<li>composition of the artefacts.</li>
</ol>
</div>
</div>

<div id="outline-container-orgaba521b" class="outline-3">
<h3 id="orgaba521b"><span class="section-number-3">7.2</span> Code patterns</h3>
<div class="outline-text-3" id="text-7-2">
<p>
Authors identify a separation of code into two types: business or
domain specific and architectural. For the architectural code, a
number of recurring patterns appear. These are effectively what we
have identified as SRAP.
</p>
</div>
</div>

<div id="outline-container-orgcb70dea" class="outline-3">
<h3 id="orgcb70dea"><span class="section-number-3">7.3</span> QVT default merging strategy</h3>
<div class="outline-text-3" id="text-7-3">
<p>
In QVT the default "key based" merging strategy means that two
elements that have the same values for key properties are merged
together.
</p>
</div>
</div>

<div id="outline-container-org8f888d3" class="outline-3">
<h3 id="org8f888d3"><span class="section-number-3">7.4</span> Building block</h3>
<div class="outline-text-3" id="text-7-4">
<p>
The unit of abstraction and composition they propose is the building
block. Presumably this is close to what we call a facet.
</p>

<p>
The composition proposed by this paper is akin to aspect oriented
weaving of blocks of text to form the final artefact. This is in
contrast to our approach which proposes such composition to be made
via facets. We should explain the pros and cons of both.
</p>
</div>
</div>

<div id="outline-container-orgafbe6d0" class="outline-3">
<h3 id="orgafbe6d0"><span class="section-number-3">7.5</span> Audit building block</h3>
<div class="outline-text-3" id="text-7-5">
<p>
The paper proposes the creation of a building block responsible for
auditing. We could probably implement similar functionality in Dogen
using facets. Backlog this as a story.
</p>

<div class="epigraph"><blockquote>
<p>
This building block specifies how to maintain a persistent audit trail
of state changes of instances of a persistent class. Each persistent
class has a corresponding audit table having a column to store
time-stamp of the state change operation, a column to store the
pre-image and a column to store the post-image.
</p>

</blockquote></div>
</div>
</div>

<div id="outline-container-org3ab320a" class="outline-3">
<h3 id="org3ab320a"><span class="section-number-3">7.6</span> Issues with building blocks</h3>
<div class="outline-text-3" id="text-7-6">
<p>
These issues are similar to those we face in dogen.
</p>

<ol class="org-ol">
<li>The level at which we model building blocks is hard to gauge.</li>
<li>Its difficult to determine where one building block starts and
another ends.</li>
<li>Separation of concerns of building blocks raises problems with
tooling.</li>
<li>Tooling needs to support debugging BB.</li>
<li>Testing of building blocks should be possible in an independent
manner.</li>
</ol>
</div>
</div>

<div id="outline-container-org7fa00e6" class="outline-3">
<h3 id="org7fa00e6"><span class="section-number-3">7.7</span> Bibliography</h3>
<div class="outline-text-3" id="text-7-7">
<ul class="org-ul">
<li>Harold Ossher, Peri L. Tarr: Hyper/J TM : Multi-Dimensional
Separation of Concerns for Java TM . ICSE 2001: 821-822: HyperJ
seems to have some similarities with stitchArchitecture-Centric
Model-Driven Web Engineering.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgcf2eec6" class="outline-2">
<h2 id="orgcf2eec6"><span class="section-number-2">8</span> Architecture-Centric Model-Driven Web Engineering</h2>
<div class="outline-text-2" id="text-8">
<p>
Link: <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.244.6866&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.244.6866&amp;rep=rep1&amp;type=pdf</a>
</p>

<p>
Escott, Eban, et al. "Architecture-centric model-driven web
engineering." 2011 18th Asia-Pacific Software Engineering
Conference. IEEE, 2011.
</p>
</div>

<div id="outline-container-org55824b1" class="outline-3">
<h3 id="org55824b1"><span class="section-number-3">8.1</span> AC-MDSD focuses on infrastructural code</h3>
<div class="outline-text-3" id="text-8-1">
<p>
AC-MDSD captures structural patterns, mainly at the architectural
level. Due to this it does not focus on behaviour. Authors propose an
approach that allows architectural focus but with access to behaviour.
</p>
</div>
</div>

<div id="outline-container-orga74cbe7" class="outline-3">
<h3 id="orga74cbe7"><span class="section-number-3">8.2</span> Advantages of MDE for web apps</h3>
<div class="outline-text-3" id="text-8-2">
<ul class="org-ul">
<li>solves the boilerplate problem of web applications, that have a lot
of commonality due to the tiered architecture.</li>
<li>provides a model level understanding of architectural patterns,
rather than having them scattered around code artefacts.</li>
<li>provides re-usability because domain concepts are encapsulated in
the model.</li>
</ul>
</div>
</div>

<div id="outline-container-org0cf5855" class="outline-3">
<h3 id="org0cf5855"><span class="section-number-3">8.3</span> Reference implementation driven approach</h3>
<div class="outline-text-3" id="text-8-3">
<p>
The approach recommended by Stahl and Volter starts by creating a
reference implementation manually and then abstracting the general
(model-based) implementation from it. It has several advantages:
</p>

<ul class="org-ul">
<li>high-quality code as a starting point, which is validated upfront
using regular developer tools.</li>
<li>the tooling produced is white-box, that is developers understand all
of the inner workings of the tool unlike in vendor supplied tooling.</li>
</ul>
</div>
</div>

<div id="outline-container-org766b043" class="outline-3">
<h3 id="org766b043"><span class="section-number-3">8.4</span> White box and black box CASE tools</h3>
<div class="outline-text-3" id="text-8-4">
<ul class="org-ul">
<li>black box is where the tools hide the internals and provide a
limited extensibility API. Users cannot modify or understand the
tool at will.</li>
<li>white box is where there is transparency of the inner workings of
the tool Dogen is a white-box tool. It is important to provide a
mapping between the model elements and the generated artefacts
(e.g. tracing) at all levels of abstraction.</li>
</ul>
</div>
</div>

<div id="outline-container-orged25322" class="outline-3">
<h3 id="orged25322"><span class="section-number-3">8.5</span> Related work</h3>
<div class="outline-text-3" id="text-8-5">
<p>
All of the approaches under analysis are dedicated solely to the
design of web applications, rather than attempting to generalise the
architectural patterns to enable applicability outside of this limited
scope. This is part of the issue Dogen tries to address.
</p>
</div>
</div>

<div id="outline-container-orgf2dab26" class="outline-3">
<h3 id="orgf2dab26"><span class="section-number-3">8.6</span> Graphical vs Textual</h3>
<div class="outline-text-3" id="text-8-6">
<p>
Graphical notation is good for expressing intent visually whereas
textual notation is good for "structured summary presentation".
</p>
</div>
</div>

<div id="outline-container-orge022bf8" class="outline-3">
<h3 id="orge022bf8"><span class="section-number-3">8.7</span> DDD Entity pattern and manager (service)</h3>
<div class="outline-text-3" id="text-8-7">
<p>
We need to review Evans (DDD) on entity pattern and manager. If what
this paper says is correct, this would be very amenable to code
generation because we separate behaviour (manager) from structure
(entity).
</p>
</div>
</div>

<div id="outline-container-org1380f53" class="outline-3">
<h3 id="org1380f53"><span class="section-number-3">8.8</span> Two-track development approach</h3>
<div class="outline-text-3" id="text-8-8">
<p>
We should write a critique of this approach, and why we have chosen to
distil its principles but not partake in the exact approach in Dogen.
</p>
</div>
</div>

<div id="outline-container-org0a17872" class="outline-3">
<h3 id="org0a17872"><span class="section-number-3">8.9</span> AC-MDSD approach with regards to extensibility</h3>
<div class="outline-text-3" id="text-8-9">
<p>
The capturing of new patterns for Dogen is expected to be done
organically. This we share in common with AC-MDSD as described in
this paper.
</p>
</div>
</div>

<div id="outline-container-orge707e8e" class="outline-3">
<h3 id="orge707e8e"><span class="section-number-3">8.10</span> Bibliography</h3>
<div class="outline-text-3" id="text-8-10">
<ul class="org-ul">
<li>find multi-stage transformation process p188 in Sthal. The approach
in dogen is to flatten the multi-stage pipeline into an
heterogeneous meta-model. We should describe in detail the
differences between the two approaches.</li>
<li>we are using model-based testing in Dogen, so we need to find
literature for this. E. Escott, P. Strooper, J. Steel, and P. King,
“Integrating Model-Based Testing in Model-Driven Web Engineering,”
in Proceedings of the Eighteenth Asia-Pacific Software Engineering
Conference, 2011</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org0eb6ac2" class="outline-2">
<h2 id="org0eb6ac2"><span class="section-number-2">9</span> A UML Profile for Feature Diagrams: Initiating a Model Driven Engineering Approach for Software Product Lines</h2>
<div class="outline-text-2" id="text-9">
<ul class="org-ul">
<li>Possompès, Thibaut, et al. "A UML Proﬁle for Feature Diagrams:
Initiating a Model Driven Engineering Approach for Software Product
Lines." Journée Lignes de Produits. 2010.</li>
<li>Link: <a href="https://hal-lirmm.ccsd.cnrs.fr/lirmm-00542800/document">https://hal-lirmm.ccsd.cnrs.fr/lirmm-00542800/document</a></li>
</ul>
</div>

<div id="outline-container-org04fb858" class="outline-3">
<h3 id="org04fb858"><span class="section-number-3">9.1</span> Objective is full lifecycle</h3>
<div class="outline-text-3" id="text-9-1">
<p>
The authors of the paper are targeting the analysis and requirements
gathering as well as the more traditional development modeling. We
have no such requirements. However they do target SPL as we do.
</p>
</div>
</div>

<div id="outline-container-orgf8673d8" class="outline-3">
<h3 id="orgf8673d8"><span class="section-number-3">9.2</span> Feature model elements</h3>
<div class="outline-text-3" id="text-9-2">
<p>
Key elements of feature model:
</p>

<ul class="org-ul">
<li>product line contains features.</li>
<li>product contains features and belongs to a product line.</li>
<li>features associated with a product may have constraints such as
require relations and mutual exclusions.</li>
<li>features have feature properties. These describe feature parameters,
or properties chosen by the user.</li>
<li>variability kinds:
<ul class="org-ul">
<li>fixed: constant</li>
<li>variable: van be changed in a product, depending on other features.</li>
<li>family variable: can change from product to product.</li>
<li>user defined: given as input by the user.</li>
</ul></li>
<li>feature can have sub-features. This is a better term than feature
bundles.</li>
</ul>
</div>
</div>

<div id="outline-container-org281083e" class="outline-3">
<h3 id="org281083e"><span class="section-number-3">9.3</span> Sub-features</h3>
<div class="outline-text-3" id="text-9-3">
<p>
As with most papers on the subject of feature models, the grouping of
features is done mainly to allow for complex relationships between the
features in the group. Our main use case is quite trivial, we just
need to group features as if in a "package". We could of course make
use of a relationship such as the <code>AndGroup</code> but its not clear why one
would implement all of the complex logic around feature relationships
if we only require the simplest use case.
</p>

<p>
However, the authors put forward the notion of a "feature set", which
seems to be the ideal candidate for our "feature bundles". Feature
sets group features from an arbitrary point of view. This is what we
do when modeling features.
</p>

<p>
Feature sets enable complex relationships between features and feature
sets themselves. We could probably use some of this - for example, if
ORM stereotypes were features, we could determine which ORM features
are enabled or disabled on the back of it. However, this would require
a generalisation of a lot of the handling that has been hard coded
thus far and its not obvious what advantages would be gained by this
generalisation.
</p>
</div>
</div>

<div id="outline-container-orgb16de8e" class="outline-3">
<h3 id="orgb16de8e"><span class="section-number-3">9.4</span> UML Component as a feature</h3>
<div class="outline-text-3" id="text-9-4">
<p>
Authors use components to model features because ports allow
expressing groups of associations of sub-features. Since we do not
have a need for complex groups, the simple grouping that attributes
enable us to do is sufficient.
</p>
</div>
</div>

<div id="outline-container-org6cc8fc5" class="outline-3">
<h3 id="org6cc8fc5"><span class="section-number-3">9.5</span> Model-relationship</h3>
<div class="outline-text-3" id="text-9-5">
<p>
Investigate what a model relationship is. Presumably it is the
meta-type for aggregation, etc.
</p>
</div>
</div>

<div id="outline-container-org133e178" class="outline-3">
<h3 id="org133e178"><span class="section-number-3">9.6</span> Bibliography</h3>
<div class="outline-text-3" id="text-9-6">
<ul class="org-ul">
<li>[ASI 06] A SIKAINEN T., M ANNISTO T., S OININEN T., “A unified
conceptual foundation for feature modelling”, SPLC ’06: Proceedings
of the 10th International on Software Product Line Conference, IEEE
Computer Society, 2006, p. 31–40.</li>
<li>Check that this paper is the same one as we read in English: [CLA
01] C LAUSS M., Untersuchung der Modellierung von Variabilität in
UML, Technische Universität Dresden, Diplomarbeit, 2001.</li>
<li>[POS ] P OSSOMPÈS T., D ONY C., H UCHARD M., R EY H., T IBERMACINE
C., V ASQUES X., “Design of a UML profile for feature diagrams and
its tooling implementation”, submitted. Gathering of requirements
for the feature model.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orge583ced" class="outline-2">
<h2 id="orge583ced"><span class="section-number-2">10</span> Generic Modeling using UML extensions for variability</h2>
<div class="outline-text-2" id="text-10">
<ul class="org-ul">
<li>Clauß, Matthias. "Generic modeling using UML extensions for
variability." Workshop on Domain Specific Visual Languages at
OOPSLA. Vol. 2001. 2001.</li>
<li>Link: <a href="http://dsmforum.org/events/DSVL01/clauss.pdf">http://dsmforum.org/events/DSVL01/clauss.pdf</a></li>
</ul>
</div>

<div id="outline-container-orgf511238" class="outline-3">
<h3 id="orgf511238"><span class="section-number-3">10.1</span> Feature models target end users</h3>
<div class="outline-text-3" id="text-10-1">
<p>
Authors agree with the general view that feature models are most
useful to model end-user related properties of the system. With Dogen
the line is blurred because our end-users are regular developers.
</p>
</div>
</div>

<div id="outline-container-org43dcfe5" class="outline-3">
<h3 id="org43dcfe5"><span class="section-number-3">10.2</span> Instantiation of models into products</h3>
<div class="outline-text-3" id="text-10-2">
<p>
The authors take the view that the product line contains generic
models which are instantiated into concrete products and parameterised
via variability. Our view is similar, but we should probably make it
clear that our models are not very generic; only the high-level
structural patterns for a product line are meant to be captured and
its not really accurate to call dogen's models "generic".
</p>
</div>
</div>

<div id="outline-container-orgcaea277" class="outline-3">
<h3 id="orgcaea277"><span class="section-number-3">10.3</span> Variation points</h3>
<div class="outline-text-3" id="text-10-3">
<p>
Variation points provide a useful way of handling variability.
</p>
</div>
</div>

<div id="outline-container-orga99a027" class="outline-3">
<h3 id="orga99a027"><span class="section-number-3">10.4</span> Generic models from Domain Engineering</h3>
<div class="outline-text-3" id="text-10-4">
<p>
The objective of a generic model is to describe a product line
architecture; it contains a model of the variability and this model
must be bound - e.g. instantiated - in order to generate concrete
software artefacts.
</p>
</div>
</div>

<div id="outline-container-org6f9825e" class="outline-3">
<h3 id="org6f9825e"><span class="section-number-3">10.5</span> Hiding of less important information</h3>
<div class="outline-text-3" id="text-10-5">
<p>
The author explains that tagged values should probably be hidden by
the tool given that they are not important for many use cases in
modeling. We will also have a similar approach when we move to the new
format for input.
</p>

<p>
We should discuss perceivability in the context of the new injector.
</p>
</div>
</div>

<div id="outline-container-orgd0cb071" class="outline-3">
<h3 id="orgd0cb071"><span class="section-number-3">10.6</span> Variation points</h3>
<div class="outline-text-3" id="text-10-6">
<p>
The variation point allows having more than one "implementation" for a
given feature, and binding it to a user choice in the user model. In
this sense, we can say that our approach also entails variation
points, but these are encoded in the logical-physical space. We need
to compare and contrast the two approaches.
</p>
</div>
</div>

<div id="outline-container-org485a1b2" class="outline-3">
<h3 id="org485a1b2"><span class="section-number-3">10.7</span> Model evolution</h3>
<div class="outline-text-3" id="text-10-7">
<p>
We should explicitly state this as a non-goal for the present version
of Dogen.
</p>
</div>
</div>

<div id="outline-container-orgc9d7412" class="outline-3">
<h3 id="orgc9d7412"><span class="section-number-3">10.8</span> Variation points and JSON</h3>
<div class="outline-text-3" id="text-10-8">
<p>
One case where we need something extremely similar to variation points
is in allowing multiple implementations of a given "feature". For
example JSON serialisation. There are many libraries in C++ that
satisfy this requirement and each user may use one library for their
own reasons. However, it would be nice to be able to state that the
JSON feature is enabled without having to concern ourselves with the
specific implementation chosen. This seems to be very close to VPs.
</p>
</div>
</div>


<div id="outline-container-org25828b4" class="outline-3">
<h3 id="org25828b4"><span class="section-number-3">10.9</span> Binding times</h3>
<div class="outline-text-3" id="text-10-9">
<p>
Authors provide a very fine grained approach to binding times. In
Dogen we took the simplest possible approach and all binding is done
at generation time. Presumably <code>build</code> time in the paper's categories.
</p>
</div>
</div>

<div id="outline-container-org1bdedac" class="outline-3">
<h3 id="org1bdedac"><span class="section-number-3">10.10</span> Variability at the model element level</h3>
<div class="outline-text-3" id="text-10-10">
<p>
We should make it clear that we do not allow "too much" (to be defined
precisely what is meant by this later) variability in the logical
dimension. In other words, you cannot use parts of a object definition
based on variability parameterisation. There is the exception of
object templates.
</p>
</div>
</div>

<div id="outline-container-org48b6881" class="outline-3">
<h3 id="org48b6881"><span class="section-number-3">10.11</span> Bibliography</h3>
<div class="outline-text-3" id="text-10-11">
<ul class="org-ul">
<li>M. Clauß, Modeling variability with UML, GCSE 2001 - Young
Researchers Workshop, September 2001</li>
<li>M. Clauß, Untersuchung der Modellierung von Variabilität in UML,
diploma thesis, August 2001. Try to locate an English translation.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgf2a85ba" class="outline-2">
<h2 id="orgf2a85ba"><span class="section-number-2">11</span> Using Aspects to Model Product Line Variability</h2>
<div class="outline-text-2" id="text-11">
<ul class="org-ul">
<li>Groher, Iris, and Markus Voelter. "Using Aspects to Model Product Line
Variability." SPLC (2). 2008.</li>
<li><a href="https://pdfs.semanticscholar.org/4c77/0315cd8151f6c162ac2f99ecc62225f4c94e.pdf?_ga=2.246561604.1739388568.1592151663-6190553.1592151663">https://pdfs.semanticscholar.org/4c77/0315cd8151f6c162ac2f99ecc62225f4c94e.pdf?_ga=2.246561604.1739388568.1592151663-6190553.1592151663</a></li>
</ul>
</div>

<div id="outline-container-orgb707bda" class="outline-3">
<h3 id="orgb707bda"><span class="section-number-3">11.1</span> Product line engineering</h3>
<div class="outline-text-3" id="text-11-1">
<ul class="org-ul">
<li>SPLE takes advantage of the commonalities between products in a
family to improve reuse.</li>
<li>products in a family differ from the features that have.</li>
<li>features are increments in functionality.</li>
</ul>
</div>
</div>

<div id="outline-container-orgb6277fe" class="outline-3">
<h3 id="orgb6277fe"><span class="section-number-3">11.2</span> MDSD and AOSD</h3>
<div class="outline-text-3" id="text-11-2">
<p>
The authors put forward a merge between these two approaches as a way
to manage the entire lifecycle of variability, as well as dealing with
the cross cutting nature of most features. They also argue that moving
to a model level abstraction permits a more compact and therefore more
manageable view of variability.
</p>
</div>
</div>

<div id="outline-container-orge0677c8" class="outline-3">
<h3 id="orge0677c8"><span class="section-number-3">11.3</span> Domain Engineering / Application Engineering</h3>
<div class="outline-text-3" id="text-11-3">
<p>
Dogen uses the exact same approach as DE/AE, except the DE portion of
the work is related to the development of Dogen itself and the AE
portion of the work is the application of Dogen to user projects, done
via configuration.
</p>
</div>
</div>

<div id="outline-container-orgded5de9" class="outline-3">
<h3 id="orgded5de9"><span class="section-number-3">11.4</span> Model-level weaving</h3>
<div class="outline-text-3" id="text-11-4">
<p>
The approach put forward results in the weaving of model elements,
something we are avoiding by design as it increases the complexity of
the modeling process quite a lot.
</p>

<p>
We need to compare and contrast the weaving that is performed by
object templates and configurations against the weaving of model
elements proposed by the paper. We should use weaving terminology for
these terms. We also should mention that after weaving you cannot tell
that weaving took place.
</p>
</div>
</div>

<div id="outline-container-org032de65" class="outline-3">
<h3 id="org032de65"><span class="section-number-3">11.5</span> Aspects for variability increases flexibility</h3>
<div class="outline-text-3" id="text-11-5">
<p>
By using aspects, the model does not need to be prepared for
variability in advance. We take the contrasting view: we only support
very limited cases of variability, and these must be exposed
explicitly. Our approach is by design less flexible.
</p>
</div>
</div>

<div id="outline-container-org7089e94" class="outline-3">
<h3 id="org7089e94"><span class="section-number-3">11.6</span> Comparison between our approach and aspects</h3>
<div class="outline-text-3" id="text-11-6">
<p>
The multidimensional approach put forward in Dogen overlaps to an
extent the AOM approach for variability in the paper. However we focus
on coarse grained features, we don't provide flexibility and
composition is only allowed in very narrow circumstances. We need to
provide a comparison of both approaches. However, we also have a clear
separation of the model elements and the variability modeling.
</p>
</div>
</div>
</div>

<div id="outline-container-org1d79f1b" class="outline-2">
<h2 id="org1d79f1b"><span class="section-number-2">12</span> A flexible code generator for MOF-based modeling languages</h2>
<div class="outline-text-2" id="text-12">
<ul class="org-ul">
<li>Bichler, Lutz. "A flexible code generator for MOF-based modeling
languages." 2nd OOPSLA Workshop on Generative Techniques in the
context of Model Driven Architecture. 2003.</li>
<li>Link: <a href="https://s23m.com/oopsla2003/bichler.pdf">https://s23m.com/oopsla2003/bichler.pdf</a></li>
</ul>
</div>

<div id="outline-container-org60fc56d" class="outline-3">
<h3 id="org60fc56d"><span class="section-number-3">12.1</span> MOmoC</h3>
<div class="outline-text-3" id="text-12-1">
<p>
Authors put forward an approach that uses XMI as input, and parses it
into XML and then uses XSLT and stylesheets to convert the XML into
source code. From experience, we know this is not a scalable approach
as its too low-level.
</p>
</div>
</div>

<div id="outline-container-org183518c" class="outline-3">
<h3 id="org183518c"><span class="section-number-3">12.2</span> Model compiler</h3>
<div class="outline-text-3" id="text-12-2">
<p>
Authors reference model compilers, and reference OMG but do not
provide a definition of a model compiler.
</p>
</div>
</div>

<div id="outline-container-orgf184bfa" class="outline-3">
<h3 id="orgf184bfa"><span class="section-number-3">12.3</span> MOmoC architecture</h3>
<div class="outline-text-3" id="text-12-3">
<ul class="org-ul">
<li>frontend is generated code that reads MOF models in XMI. Supports
targetting the generation to other representations that are
MOF-compliant.</li>
<li>middle-end is supplement by user defined modules. At present it has
a type mapping and naming resolution modules. Middle-end transforms
types into XML</li>
<li>backend is made up of XSLT that generate the implementation code.</li>
</ul>


<p>
Review of the paper: Groher, Iris, and Markus Voelter. "Using Aspects
to Model Product Line Variability." SPLC (2). 2008.
</p>
</div>
</div>
</div>
<div id="outline-container-orge6369a8" class="outline-2">
<h2 id="orge6369a8"><span class="section-number-2">13</span> A Comparison of Generative Approaches: XVCL and GenVoca</h2>
<div class="outline-text-2" id="text-13">
<ul class="org-ul">
<li>Paper: Blair, James, and Don Batory. "A Comparison of Generative
Approaches: XVCL and GenVoca." Technical report, The University of
Texas at Austin, Department of Computer Sciences (2004).</li>
<li>Link: <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.457.1399&amp;rep=rep1&amp;type=pdf">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.457.1399&amp;rep=rep1&amp;type=pdf</a></li>
</ul>
</div>

<div id="outline-container-orge6d1c78" class="outline-3">
<h3 id="orge6d1c78"><span class="section-number-3">13.1</span> Compositional Design</h3>
<div class="outline-text-3" id="text-13-1">
<p>
The idea is to start with a core and add progressively to it, with
each addition roughly corresponding to a feature. We propose a
compositional approach but based on multi-dimensionality.
</p>
</div>
</div>

<div id="outline-container-org0bf3762" class="outline-3">
<h3 id="org0bf3762"><span class="section-number-3">13.2</span> References</h3>
<div class="outline-text-3" id="text-13-2">
<ul class="org-ul">
<li>Programming by difference: R.E. Johnson and B. Foote, “Designing
Reusable Classes”, Journal of Object-Oriented Programming,
June/July 1988.</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org249633f" class="outline-2">
<h2 id="org249633f"><span class="section-number-2">14</span> An evaluation of the Graphical Modeling Framework GMF based on the development of the CORAS tool</h2>
<div class="outline-text-2" id="text-14">
<ul class="org-ul">
<li>Paper: Seehusen, Fredrik, and Ketil Stølen. "An evaluation of the
graphical modeling framework (gmf) based on the development of the
coras tool." International Conference on Theory and Practice of
Model Transformations. Springer, Berlin, Heidelberg, 2011.</li>
<li>Link: <a href="http://hjem.ifi.uio.no/ketils/kst/Articles/2011.ICMT.pdf">http://hjem.ifi.uio.no/ketils/kst/Articles/2011.ICMT.pdf</a></li>
</ul>
</div>
<div id="outline-container-orgb791770" class="outline-3">
<h3 id="orgb791770"><span class="section-number-3">14.1</span> Tagging in GMF</h3>
<div class="outline-text-3" id="text-14-1">
<p>
Investigate how GMF code that is modified after code generation is
tagged so that the generator knows not to overwrite it.
</p>

<p>
Actually XPand allows for annotations in methods of the generated code
that indicate whether the methods should be overwritten or not.
</p>
</div>
</div>

<div id="outline-container-org14f462b" class="outline-3">
<h3 id="org14f462b"><span class="section-number-3">14.2</span> Packaging issues</h3>
<div class="outline-text-3" id="text-14-2">
<p>
Authors argue that for a Tool B that reuses Tool A, it is not possible
to merely reference a package that contains both the source code of A
and the models of A; instead they ended up copying and pasting A into
B. It is not clear why the packaging of model plus source does not
work.
</p>
</div>
</div>
<div id="outline-container-org80df858" class="outline-3">
<h3 id="org80df858"><span class="section-number-3">14.3</span> Avoid human interactions in generations</h3>
<div class="outline-text-3" id="text-14-3">
<p>
Authors argue that the generation process should be as mechanical as
possible, and should not have any human interacts, particularly using
UIs.
</p>
</div>
</div>
</div>

<div id="outline-container-orgad8d414" class="outline-2">
<h2 id="orgad8d414"><span class="section-number-2">15</span> Features as transformations: A generative approach to software development</h2>
<div class="outline-text-2" id="text-15">
<ul class="org-ul">
<li>Paper: Vranić, Valentino, and Roman Táborský. "Features as
transformations: A generative approach to software development."
Computer Science and Information Systems 13.3 (2016): 759-778.</li>
<li>Link: <a href="https://pdfs.semanticscholar.org/7f20/ee0ef94ba20161611c2ae184e6040f9d2fe1.pdf?_ga=2.47007141.386256099.1594564659-1149343892.1591869910">https://pdfs.semanticscholar.org/7f20/ee0ef94ba20161611c2ae184e6040f9d2fe1.pdf?_ga=2.47007141.386256099.1594564659-1149343892.1591869910</a></li>
</ul>
</div>

<div id="outline-container-org3242519" class="outline-3">
<h3 id="org3242519"><span class="section-number-3">15.1</span> Feature selection</h3>
<div class="outline-text-3" id="text-15-1">
<p>
Authors claim that feature selection is a much more complex process
than merely enabling a component. We are striving to make it so.
</p>
</div>
</div>

<div id="outline-container-orgb511593" class="outline-3">
<h3 id="orgb511593"><span class="section-number-3">15.2</span> Feature interaction</h3>
<div class="outline-text-3" id="text-15-2">
<p>
The fact that features interfere with each other and may require
adaptation in order to be applied to the system.
</p>
</div>
</div>

<div id="outline-container-orgbef6a51" class="outline-3">
<h3 id="orgbef6a51"><span class="section-number-3">15.3</span> Classification of transforms</h3>
<div class="outline-text-3" id="text-15-3">
<p>
Authors provide a simple classification of transforms which can be
used also to describe the SRAPs in Dogen.
</p>
</div>
</div>
</div>

<div id="outline-container-orgf3daf4f" class="outline-2">
<h2 id="orgf3daf4f"><span class="section-number-2">16</span> Translating Alloy Specifications to UML Class Diagrams Annotated with OCL</h2>
<div class="outline-text-2" id="text-16">
<ul class="org-ul">
<li><a href="https://repositorium.sdum.uminho.pt/bitstream/1822/35641/1/848.pdf">https://repositorium.sdum.uminho.pt/bitstream/1822/35641/1/848.pdf</a></li>
</ul>
</div>
</div>

<div id="outline-container-orgd0d9885" class="outline-2">
<h2 id="orgd0d9885"><span class="section-number-2">17</span> Agile MDA</h2>
<div class="outline-text-2" id="text-17">
<ul class="org-ul">
<li>"An executable model, because it is executable, can be constructed,
run, tested and modified in short incremental, iterative cycles."
Executability is not a requirement for agility. Dogen models provide
exactly this type of development.</li>
<li>they fall into the voltaire pitfall: "To eliminate the verification
gap and enable immediate delivery of fragments of the system, what
we need is a highly abstract modeling language that focuses on a
single subject matter—the subject matter of interest to the
customer—and yet is specific and concrete enough to be executed, an
executable model."</li>

<li>Model Compilers: "A model compiler takes a set of executable UML
models and weaves them together according to a consistent set of
rules. This task involves executing the mapping functions between
the various source and target models to produce a single
all-encompassing metamodel (aka “the grungiest”) that includes all
the structure, behavior and logic—everything—in the system. The
final mapping from this metamodel can be done in several ways. One
approach to defining mapping functions is to use an archetype, which
are especially suited to manipulating text. Weaving the models
together at once addresses the problem of architectural mismatch, a
term coined by David Garlan to refer to components that do not fit
together without the addition of tubes and tubes of glue code, the
very problem MDA is intended to avoid! A model compiler imposes a
single architectural structure on the system as a whole."</li>
</ul>
</div>
</div>

<div id="outline-container-org43c929e" class="outline-2">
<h2 id="org43c929e"><span class="section-number-2">18</span> Model-driven Development of Complex Software: A Research Roadmap</h2>
<div class="outline-text-2" id="text-18">
<ul class="org-ul">
<li><a href="papers/Model-driven%20Development%20of%20Complex%20Software:%20A%20Research%20Roadmap.pdf">paper</a></li>
<li>MDA talks about CIM, PSM, PIM. In dogen we advocate a mix of PIM and
PSM. Users should try as much as possible to keep their models PIM,
but if need be, just drop to PSM. CIM and PIM are really a concept
that is meaningful at a level higher than dogen.</li>
<li>we do not think that automated platform migrations are a realistic
target so we do not support this use case.</li>
<li>we do not believe in the industrialisation of software
development. The activity is too complex to be automated. However,
this does not mean that a small amount of automation is not
possible. Voltaire: le mieux est l'ennemi du bien.</li>
<li>"Reusable forms of development experience (e.g., patterns,
templates, guidelines, transformations) are associated with each
viewpoint, and thus accessible in the context of that viewpoint." We
are trying to do this with facets.</li>
<li>separation of design concerns: facets can be understood as different
design concerns. maybe there is a need to talk about macro-concerns
(architectural) and micro-concerns (class-level). Facets can span
both but we are only worried about micro for now. However, when it
comes to describe the generation model we will have to address this
issue.</li>
<li>it seems facets are an AOM (aspect oriented modeling)
approach. However, instead of allowing multiple viewpoints and
composition, we treat aspects/facets as variation points and the
composition is pushed down to the (feature) configuration
level. This solves a lot of the difficulties around composition of
primary and aspect models.</li>
<li>facets focus only on trivial behaviours, making composition
trivial. Also, in general, they are implemented external to the
class so that merging is not an issue and its much easier to isolate
conflicts. However, this must be done manually by the designer of
the class, and stipulated as a rule (e.g. facet a depends on b and
conflicts with c).</li>
</ul>
</div>
</div>

<div id="outline-container-org53e5e9e" class="outline-2">
<h2 id="org53e5e9e"><span class="section-number-2">19</span> A meta-model for language-independent refactoring</h2>
<div class="outline-text-2" id="text-19">
<ul class="org-ul">
<li><a href="papers/A%20Meta-model%20for%20Language-Independent%20Refactoring.pdf">paper</a></li>
<li>Why they created their own metamodel: "Another reason is that models
such as UML [18] are directed towards object-oriented analysis and
design rather than source code representation." This also applies to
dogen.</li>
<li>the pre and post conditions may have some use for dogen
validation. For example adding new classes, methods etc.</li>
<li>we could also reuse the analysis on the costs:
<ul class="org-ul">
<li>"Increased complexity of algorithms. To deal with multiple
languages the underlying model needs to be general enough to cover
the supported languages."</li>
<li>"Mapping back to the actual code. The actual code changes are,
naturally, language specific. However, in some cases the concepts
that are generalized at the language-independent level (e.g. Java
constructors are methods, Java interfaces are classes) need to be
mapped back to their language-specific kind, because at the code
level they need to be dealt with differently than their ‘normal’
counterparts."</li>
<li>"Language-independent defaults. To keep some refactorings as
language independent as possible, some defaults are used."</li>
</ul></li>
<li>similarly, section "Not all language differences can be abstracted
from." also has a lot of good points.</li>
</ul>
</div>
</div>

<div id="outline-container-org3731310" class="outline-2">
<h2 id="org3731310"><span class="section-number-2">20</span> Metrics on Feature Models to Optimise Configuration Adaptation at Runtime</h2>
<div class="outline-text-2" id="text-20">
<ul class="org-ul">
<li>paper not in our library</li>
<li>a use case for this paper is facet enablement, In an ideal world, we
should be able to look at the included files in a project and
backout the used facets. We can then determine what is not being
used (diff generated files from included files). Then we can propose
a list of facets to disable (or types to remove) to the user. This
also solves the TB problem: delete types that are not in use. It has
to be robust enough to understand graphs of types (e.g. no includes
of base, but derived etc). Interestingly, we only need the includes
(no deep parsing of the AST). However, we do need to know of all
consumers of a model. Perhaps we could make use of public/internal
separation: types marked as public are excluded. The second problem
is that we cannot easily patch the model with the resulting facet
enablement.</li>
<li><p>
however the approach given on this paper does not apply directly to
our needs because we never need to do a search in a space. Our use
cases are:
</p>
<ul class="org-ul">
<li>1. user selects a feature configuration, we validate it. If
invalid, throw and tell the user why. User has to manually fix it.</li>
<li>2. user selects a feature configuration and we automatically
enable/disable any features based on dependencies. If we can't
enable a feature (not supported), throw and tell the user (or
possibly disable the graph using the feature).</li>
<li>3. user points to a code base and we determine what files have
been included. From this we back out used features. We diff this
against the list of generated features and automatically propose a
feature minimal configuration.</li>
</ul>

<p>
None of these cases requires searching through a feature space.
</p></li>
</ul>
</div>
</div>

<div id="outline-container-org0d1d224" class="outline-2">
<h2 id="org0d1d224"><span class="section-number-2">21</span> A UML profile for feature diagrams</h2>
<div class="outline-text-2" id="text-21">
<ul class="org-ul">
<li><a href="papers/A%20UML%20profile%20for%20feature%20diagrams:%20Initiating%20a%20model%20driven%20engineering%20approach%20for%20software%20product%20lines.pdf">paper</a></li>
<li>this meta-model is very useful for dogen. We could implement it as a
model and then extend it with the requirements needed for dogen (is
it a global feature or element feature, more fine-grained types,
etc). The model should expose annotations as a flat representation
of the rich feature model. It should convert from annotations into
the model, performing validation. It should also validate
dependencies (build a graph of features).</li>
<li>in addition, we need to create a UML profile to expose the model,
and then create a dogen model with the profile. The generated code
should read annotations and return instantiated features with the
correct types.</li>
<li>we should try to make this model generic so that it can be used by
applications. However, given that there is no notion of annotations,
we probably need a different way of expressing it. Perhaps we could
use boost property tree. In fact that is the right approach: boost
property tree becomes the underlying representation; we make
<code>Annotatable</code> contain a property tree; the generated code generates
the C++ data types that represent the configuration, and it has a
load/save (not quite those names) to serialise and deserialise
itself from a property tree. When defining a feature we need to
supply its "path", e.g. the path to the class. The path to the
attribute is inferred by the name. Now this code is completely
agnostic to code generation - it is merely a way to do
configuration. We just need to add the notion of scopes so that we
can distinguish between element and model level options. Actually
the notions of global and local are not dependent on code
generation, but what global and local mean are.</li>
<li>for extra bonus points, it would be nice to be able to map features
to program options as well; instead of property tree, we would
generate the code to setup the program options as well as the class
to represent the options. The user could specify the implementation
mapping as meta-data (a feature).</li>
<li>note that we can just map a feature set to a class because then its
not possible to define the complex relationships between features
(and/or etc). These are required particularly if we want a program
options mapping. The approach in the paper is not ideal but at least
it solves this problem.</li>
</ul>
</div>
</div>

<div id="outline-container-orgb30eb43" class="outline-2">
<h2 id="orgb30eb43"><span class="section-number-2">22</span> AndroMDA</h2>
<div class="outline-text-2" id="text-22">
<ul class="org-ul">
<li><a href="papers/AndroMDA%20-%20German.pdf">paper</a> (german)</li>
<li>MDA: "The transformation of the models into platform-specific source
code requires tools and frameworks."</li>
<li>AndroMDA generates ready to use applications; we focus on extracting
simple structural functions.</li>
<li>AndroMDA is designed to fit into MDA, we are targeting unorthodox
practitioners.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd1d12ee" class="outline-2">
<h2 id="orgd1d12ee"><span class="section-number-2">23</span> Construction and Evolution of Code Generators</h2>
<div class="outline-text-2" id="text-23">
<ul class="org-ul">
<li><a href="papers/Construction%20and%20Evolution%20of%20Code%20Generators:%20A%20Model-Driven%20and%20Service-Oriented%20Approach%20-%202013.pdf">thesis</a></li>
<li>"In essence, even though there are code generator workbenches that
help the programming expert to design dedicated code generators,
more high-level activities like process support, variability
management, or product lining are not foreseen."</li>
<li>jorges code generator has support for constraint solving and model
checking.</li>
<li>jorges points to AndroMDA, seems very similar to what we are trying
to do. We need to find more about it and explain why we are
different.</li>
<li>one of the problems of this approach is that we now have to deal
with SIBs and jABC: a completely different paradigm from how
developers are used to working. What we really need is an
abstraction that is very close to the code first.</li>
<li>the library of common SIBs is similar in spirit to a library of
common facets.</li>
<li>our target is only the developer. There are no features for domain
experts, business analysts, etc.</li>
<li>we do not want XMDD given it aims for full generation. We need
something more like Agile MDD with barely good enough models and
modeling.</li>
<li>we need to look at their constraints checker and see if any of the
constraints or the approach can be lifted for dogen.</li>
<li>in order to do model checking one needs to be familiar with modal mu
calculus. Most regular developers won't so very few will add checks.</li>
<li>facets are part of our strategy of variant management. The variation
points are metadata parameters that allow configuration of the
facet.</li>
<li>we have a similar notion of execution context, but ours is strongly
typed. This may not be flexible enough for its requirements.</li>
<li>the context could also contain the error stack with all errors found
so far (validation etc).</li>
<li>unlike genesys, in dogen we have a fixed interface for facets and
they are always consumed via the metadata. We don't expect users to
create new code generators, we only allow variability via
metadata. Two use cases: 1) code generator developer, either does a
new kernel (very infrequent) or adds a new facet to the facet
library 2) code generator user: configures the variability.</li>
<li>benchmarking is probably helpful: figure out where in dogen time is
going. We already have probing for this but it does not give details
on individual facets.</li>
<li>meta-information about facets would be helpful. It is useful for
example for listing the available facets (with a description), their
configuration parameters, their dependencies. Similarly with kernels
and backends.</li>
<li>facets and aspects are implementations of features.</li>
<li>we should have exactly a three-phase approach in dogen: 1)
initialisation 2) transformation 3) generation. We already have this
except we mapped the generation phase as a transform. However, in
the thesis we can describe the three phases like Jorges (p119). This
also means that all of the "static" registration we have at present
can now be placed into the initialisation phase. If we had a
top-level "phase manager" we could simply call the phases from
main. We must also keep in mind the "service" approach, where we may
process more than one model (e.g. transformation + generation are
applied repeatedly).</li>
<li>however, the three phase approach has to do with orchestration (it
will manifest itself as classes or methods in orchestrator). The
code structure should follow a frontend, middleend, backend
pipeline. This is more suitable than external, modeling and
generator.</li>
<li>we need to also have an ecore example/case study where we should
make the same points as ch7: dogen does something that no other EMF
tool does (facets).</li>
</ul>
</div>
</div>

<div id="outline-container-org3e46640" class="outline-2">
<h2 id="org3e46640"><span class="section-number-2">24</span> Bridging the Gap Between Features and Models</h2>
<div class="outline-text-2" id="text-24">
<ul class="org-ul">
<li><a href="papers/Bridging%20the%20Gap%20Between%20Features%20and%20Models.pdf">paper</a></li>
<li>the variant model is in effect a feature configuration. A
realisation of the feature model. The variant model is used in the
solution space to determine what features to include.</li>
<li>there are two types of features: "We differentiate two types of
features: features that have realisations connected to specific
points in the core and features that add duplicated artefacts
scattered across various points in an aspectual manner."</li>
<li>"In our work we differentiate two feature types: collaborative
features and aspectual features." This separation is very useful for
dogen features: we need to classify dogen features, and explain how
they map implementation-wise. However, we need to also state that we
do not offer a generic mechanism to the user - instead, the user
should use whatever technologies are available for modeling.</li>
<li>in order to meet our requirements, dogen does not rely on any
existing MDE technology; it is designed to integrate with existing
tooling but does not require it. Thus we do not make use of ecore
etc.</li>
</ul>
</div>
</div>

<div id="outline-container-org5ba685c" class="outline-2">
<h2 id="org5ba685c"><span class="section-number-2">25</span> Generating Aspect Code from UML Models</h2>
<div class="outline-text-2" id="text-25">
<ul class="org-ul">
<li><a href="papers/Generating%20Aspect%20Code%20from%20UML%20Models.pdf">paper</a></li>
<li>"Code generation improves developer productivity, ensures
syntactical correctness and reduces errors when mapping model to
code."</li>
</ul>
</div>
</div>

<div id="outline-container-orgcc6372e" class="outline-2">
<h2 id="orgcc6372e"><span class="section-number-2">26</span> State of the art of QVT: a model transformation language standard</h2>
<div class="outline-text-2" id="text-26">
<ul class="org-ul">
<li><a href="papers/LNCS%20-%20Applications%20of%20Graph%20Transformations%20with%20Industrial%20Relevance%20-%202007.pdf">paper</a></li>
<li>explains the motivation behind PSM/PIM: "This classification is
motivated by the constant change in implementation technologies and
the recurring need to port software from one technology to another."</li>
<li>the ideas behind QVT are interesting, but in some ways the DSL makes
it harder to understand them. If instead we simply had a library
with MOF and then say two metamodels (MOF instances): relational
model and UML model. Then we could define a function that
transformed one metamodel element to another, say <code>class</code> to
<code>table</code>. So in terms of programming, one could imagine a reflection
based API with "objects" where each object could have a metatype
(recursively, until reflexivity takes over):</li>
</ul>

<pre class="example" id="org50b658c">
class o;
o.name("my_class");
...
if (o.metatype() == class) {
    table t;
    t.name(o.name());
}
</pre>

<ul class="org-ul">
<li>this is most useful if the code generation model is able to generate
arbitrary code - e.g. the structural patterns which we are encoding
into the code generation metamodel are now expressed as
transforms. This allows for arbitrary structural patterns, but it
does mean: a) the code generation metamodel must be very generic b)
the transforms are much more complex.</li>
<li>in the case of a financial model, we would create a DSL with all of
the financial products. Then, we'd instantiate the DSL with the
actual products supported by the company. So a vanilla option for
example is implemented as a deliverable product, with cashflows
etc. Then we transform this model into several other metamodels
(code generation metamodel, UI metamodel, etc). For example the UI
metamodel could have concepts such as form, button etc. To represent
a vanilla, we would transform the financial product metamodel into
the UI metamodel:</li>
</ul>

<pre class="example" id="org7443370">
vanilla v;
form f;
f.title(v.name());
...
</pre>

<p>
Each of the individual elements of the products will have mappings
to the UI metamodel. Then, the UI metamodel is code generated by a
kernel specialised on the UI metamodel. Metamodels and generators
come in pairs. These pairs are kernels: OO, relational, XML/XSD, UI,
etc. Features can be implemented either as facets/aspects on an
existing kernel (e.g. ODB for relational) or, if they have their own
metamodel, as a kernel (e.g. relational kernel). Kernels can depend
on other kernels (e.g. the relational kernel depends on the OO
kernel because it creates c++ code that reads/writes c++ objects to
a relational database). Users create their metamodels and models in
ecore, which we then transform to the kernel models.
</p>
</div>
</div>

<div id="outline-container-org2e957db" class="outline-2">
<h2 id="org2e957db"><span class="section-number-2">27</span> Generative Programming Using Frame Technology</h2>
<div class="outline-text-2" id="text-27">
<ul class="org-ul">
<li><a href="papers/Generative%20Programming%20Using%20Frame%20Technology.pdf">paper</a></li>
<li>in general it seems there isn't much of frame technology we can
reuse. However there are a few concepts: frame layers, framework and
frame libraries. However, where frames are very configurable and
reusable, facets are designed to have as few variation points as
possible and to be reused as is. You either need boost serialisation
or you do not - there isn't a lot of scope for variation points.</li>
<li>dogen is a single-phased generator: "A single-phased generator (see
Figure 3.12:2) works sequentially. It takes its input (see Figure
3.12:1) which consists of specific parameters and commands mixed
with code of the target language and processes it. In case of a
frame processor these are the frames and functions. During the
evaluation of the input source, the generator can use data from a
repository (see Figure 3.12:3) to enhance or check the input. A
repository in this context means any kind of data storage that
contains configuration data (e.g. a database or a
XML-file). Finally, it produces an output (see Figure 3.12:5) with
the production process running mostly in the same order as the input
is structured. These outputs are often volatile. Every piece of
generated source code is instantaneously released and can not be
further processed, or evaluated for the processing of other source
code [DST02b, p. 15]."</li>
<li>the concept of frames and frame instances is useful: maybe we can
use it when defining the facet space and the implementation
space. But really artefacts are archetype instances already.</li>
<li>frame processors use command line arguments. We are against this
approach. We should probably explain why variability should be
contained within the model and not leaked through to the command
line.</li>
</ul>
</div>
</div>

<div id="outline-container-org5c80c1a" class="outline-2">
<h2 id="org5c80c1a"><span class="section-number-2">28</span> Ecore.Fmp: A Tool For Editing And Instantiating Class Models As Feature Models</h2>
<div class="outline-text-2" id="text-28">
<ul class="org-ul">
<li><a href="papers/Ecore.Fmp:%20A%20Tool%20For%20Editing%20And%20Instantiating%20Class%20Models%20As%20Feature%20Models.pdf">paper</a></li>
<li>typical usage of EMF "Ecore is a part of the Eclipse Modeling
Framework (EMF), a framework that provides a practical foundation
for building modeling tools. When using EMF, users typically first
create a metamodel for their domain in the form of an Ecore class
model. Next, the users may use a code generator that generates an
implementation of the metamodel or they can utilize the metamodel
using reflection. The code generator Figure 2 shows a feature model
that represents the class can also create a specialized graphical
tree editor for ing and editing object models for the given
metamodel."</li>
<li>ecore annotations are similar to ours: "Ecore, similarly to
Essential MOF, also supports a tagging mechanism which allows
annotating each class model element with a set of key-value
pairs. In Ecore, instances of the class EModelElement can contain
many instances of the class EAnnotation , which, in turn, has a
String to String map that represents key to value pairs. The
complete metamodel of Ecore can be found at [1]."</li>
<li>perhaps what we are trying to do is to model the feature model as a
fixed set of classes - in effect, the feature model metamodel; then
add the logic around it (graph, dependencies and so forth) as
manually written code; then allow dogen developers to define a
concrete feature model (an instance) by making use of a UML profile,
which then generates code that instantiates the feature model
instance; then when we are processing a user UML model, the user
supplies a feature configuration which is an instance of the dogen
feature model instance. Its all done at run time. We do not need to
do this at run time for all of the features that make up the core of
Dogen - we could have properly typed c++ classes. Then there should
be a type layer which is part of the code generated feature model
instance which can be instantiated from the feature model
metamodel. We need to use the ecore.fmp mappings to convert say
feature groups into classes and features into properties. The
generated code automatically knows how to try to bootstrap one of
these classes from features. In effect we have three layers:
<ul class="org-ul">
<li>annotation: KVP layer</li>
<li>feature model: dynamic layer with feature model metamodel.</li>
<li>feature model instance: set of c++ classes with a typed
representation of the actual feature model. Inject typing into the
feature model.</li>
<li>feature configuration: user UML diagram making use of the
available features.</li>
</ul></li>
<li>interestingly, feature models do not have any binding in terms of
scope to metamodel elements. Thus the FM metamodel will not have
this concept. However, for dogen we need this. We could introduce
the notion of local and global - in practice this is sufficient for
all of the existing use cases. Or we may just have to hack the
feature metamodel specifically for dogen.</li>
<li>which perhaps raises the point of: are features not just modeling
elements, present in the dogen codegeneration metamodel? This would
make life easier and add more research weight. If we did fold the
feature metamodel into the metamodel this would have the following
consequences:
<ul class="org-ul">
<li>we would need a transformation that creates value objects from
features and converts them into the c++ typesystem.</li>
<li>we need a mapping that reads these typed objects in and out of
feature metamodel elements.</li>
<li>we need some manually crafted code that converts an annotation
into instances of these feature metamodel elements.</li>
<li>we need manually crafted code that handles global/local,
overrides, etc.</li>
<li>we need a template that injects instances of the feature metamodel
elements.</li>
<li>we need some way of registering the c++ types so that we can
generate them from the feature metamodel. Or perhaps this is done
on the fly as users ask for them.</li>
<li>we must not bind feature metamodel directly to annotations; it
should work against any KVP representation with the concepts of
local and global.</li>
<li>one slight snag though: in order to use the feature metamodel in
their own code, users now need to link against the dogen
metamodel. So this is a dogen specific thing. If however, we were
to construct the needle model and make it independent of dogen, we
could move it there. It would make more sense to have a feature
model as an external library like <a href="https://github.com/EmilianoSanchez/Feature-Model-Optimization">Feature Model Optimization</a>. Or
maybe there are two aspects to it: first there is the external
library that does all the computations and optimisations to FM and
provides a non-typed API to features. Then there is the dogen
support, which does several things: 1) maps features to codegen
metamodel; 2) instantiates the external library based on the
metamodel 3) creates strongly typed representations of
features; 4) maps external library to strongly typed.</li>
</ul></li>
<li>future work: how to plug user defined feature models back into dogen
such that users can make structural features (classes, attributes)
dependent on feature configuration. We do not have a use case for
this. at present there are two separate worlds: 1) general feature
model 2) dogen's usage of general feature model for internal
purposes 3) dogen's generation of helper code on top of general
feature model so that users can make use of it. This would be a
fourth use case.</li>
<li>the paper seems to allude to a solution on the cyclical references
in feature configuration, though its not obvious how it works: "In
the case of feature configuration, the upward branch traversal is
stopped when an instance is reached. If none of the elements in the
cyclic containment are a root feature, then the user is required to
annotate the desired EClass that should be the root feature using
the annotation root as discussed earlier."</li>
</ul>
</div>
</div>

<div id="outline-container-orge3e4326" class="outline-2">
<h2 id="orge3e4326"><span class="section-number-2">29</span> Towards Separation of Concerns in Model Transformation Workflows</h2>
<div class="outline-text-2" id="text-29">
<ul class="org-ul">
<li><a href="papers/Towards%20Separation%20of%20Concerns%20in%20Model%20Transformation%20Workflows.pdf">paper</a></li>
<li>definition: "modeling workflow (workflow): It emphasizes that there
may be other tasks to specify than only model transformations, for
example model loading, storing, checking, or code generation."</li>
<li>shortcomings of workflow technologies: 1) integration effort: hard
to add further transformation technologies 2) flexibility: hard to
specify additional processes 3) inadequate variability management
support.</li>
<li>this paper provides a basic analytical framework with which to
evaluate modeling workflows. We could apply it to Dogen and explain
why we have taken the present approach. Its probably beyond the
scope of the thesis, but suitable for the Dogen manual.</li>
<li>we can also benefit from making workflows more explicit with named
components. This could be the start of the natural evolution towards
a DSL. Types of workflow elements: model checkers, creators,
transformers, finishers, chains.</li>
<li>they defend the integration of multiple technologies, whereas we are
against it. It raises the complexity bar even further. We believe
there should be interfaces defined at a higher level such as using
ecore as an input model to the generator. We have no bearing in what
is done prior to the generation of the ecore model. The code
generation workflow is completely decoupled from any preceding
workflow that was used to generate the ecore model.</li>
<li>using a DSML for workflow generation is similar to using workflow
engines for other purposes: you end up encoding all of the FSM logic
in fragments of XML that are extremely hard to debug and manage. You
loose all of the affordances that regular GPL code gives you. It may
appear to be more expressive but the end result is that you spend
more time trying to get things to work.</li>
<li>this hits the nail on the head with our notions of fractal
engineering: "The strict separation of concerns, which we foster
throughout this paper, has a particular reason: we especially are
interested in the terms and conditions for the decomposition and
composition of whole product lines. Product generation of a compound
product originated from several product lines is a potentially
highly complex task. Several product generation processes, one of
each product line, may have to interact to create the final
product. Thus, a clear interface for interaction is necessary, and,
for model-driven product lines, model transformation workflows
result to be a promising integration point for that purpose."</li>
<li>however, our approach is to decouple product interfaces. A product
line may make use of another product's interface but we should never
need to assemble one product from several products. The unit of
development is the product, and product lines make products. A
product may rely on other systems (e.g. association) but it is not
"composed" of other products from a code generation perspective. It
is logically, but not physically. This is in order to avoid the
problems highlighted above.</li>
</ul>
</div>
</div>

<div id="outline-container-orgea94e0e" class="outline-2">
<h2 id="orgea94e0e"><span class="section-number-2">30</span> Classification of Model Transformation Approaches</h2>
<div class="outline-text-2" id="text-30">
<ul class="org-ul">
<li><a href="papers/Classification%20of%20Model%20Transformation%20Approaches.pdf">paper</a></li>
<li>it seems what we are doing is in the spirit of frame processing. We
need to read up on frame processing.</li>
<li>we could explain our transforms from external models to
code-generation model to augmented model with this "Why are
model-to- model transformations needed? When bridging large
abstraction gaps between PIMs and PSMs, it is easier to generate
intermediate models rather than go straight to the target PSM."</li>
<li>XDE seems to be interesting. Parameterisation is what we already do
for facets. They seem to tackle patterns.</li>
</ul>
</div>
</div>

<div id="outline-container-org3673db9" class="outline-2">
<h2 id="org3673db9"><span class="section-number-2">31</span> Feature-Based Survey of Model Transformation Approaches</h2>
<div class="outline-text-2" id="text-31">
<ul class="org-ul">
<li><a href="papers/Feature-Based%20Survey%20of%20Model%20Transformation%20Approaches.pdf">paper</a></li>
<li>we need to review dogen transformations with regards to the features
in this paper and try to see where we can make the interfaces
reflect this terminology. For example, we seem to loop through the
model and then find elements of interest to mutate. They seem to
suggest we should first query/filter the model using a rule and then
apply the mutation to the result of the query/filter. This would
perhaps improve the code. The query result could be a typed
container (pointer container?) with the elements that match. That
means we can then start to converge towards a rule engine. However,
we'd have to go through all the transforms and see if they would all
benefit from this split.</li>
<li>we use imperative programming for the rules.</li>
<li>We make use of both: "Transformations with source and target domains
conforming to a single metamodel are referred to as endogenous or
rephrasings; whereas transformations with different source and
target metamodels are referred to as exogenous or
translations."</li>
<li>Dogen supports transformation tracing, which we called probing.</li>
<li>we seem to use control parameters quite a lot. They are used to
convey feature configuration. "Parameterization. The simplest kind
of parameterization are control parameters, which allow passing
values as control flags (see Figure 14). Control parameters are
useful to implement policies. For example, a transformation from
class models to relational schemas could have a control parameter
specifying which of the alternative patterns of object-relational
mapping should be used in a given execution."</li>
<li>Dogen uses the mechanisms of the language to organise transforms
into chains.</li>
<li>not a big fan of the usage of the word rule.</li>
<li>our source-target relationship is chosen based on the needs of the
transform. Sometimes we use in-place, in other cases (such as
merging and translation) we use distinct source and targets.</li>
<li>we do not support incrementality by design. Makes the generator more
complex.</li>
<li>all of our transforms are unidirectional, with the exception of
model merging. Here we need some kind of way of reading the
protected region into the artefact.</li>
<li>we extend the <a href="http://jamda.sourceforge.net/">Jamda</a> approach:</li>
</ul>

<div class="epigraph"><blockquote>
<p>
Jamda is an open-source framework for building application generators
which create Java code from a model of the business domain. Instead of
a generator which produces one fixed architecture, Jamda provides a
structure and building blocks so that you can build an application
generator which does exactly what your project needs. It includes a
sample generator for J2EE applications which can either be tailored to
the needs of your J2EE project, or used as the basis of a generator
for a completely different architecture.
</p>

<p>
From a UML model of the application domain, a generator created with
Jamda could create the code for all the standard functions of
locating, displaying and updating the business objects in the
application. The developer would then concentrate on the
application-specific business logic, which is merged into the
generated application. In a typical application, the developer would
only need to write around 20% of the total system code.
</p>

<p>
Is it a Model Driven Architecture tool?
</p>

<p>
An application generator built using Jamda would perform the role of a
model compiler in the Object Management Group's Model Driven
Architecture specification. It takes a UML domain model as input, adds
new classes to the model to support the implementation, and then
generates executable code.
</p>

</blockquote></div>

<ul class="org-ul">
<li>we follow exactly the same approach: "The openArchitectureWare
Generator Framework propagates the idea of separating more complex
source access logic, which might need to navigate and gather
information from different places of the source model, from
templates by moving the logic into user-defined operations of the
source-model elements." We need to explain that our metamodel is
designed with this in mind.</li>
<li>we have chosen the direct manipulation approach for the M2M
transforms:</li>
</ul>

<div class="epigraph"><blockquote>
<p>
Direct-Manipulation Approaches
</p>

<p>
These approaches offer an internal model representation plus some API
to manipulate it, such as JMI.  They are usually implemented as an
object-oriented framework, which may also provide some minimal
infrastructure to organize the transformations (e.g., abstract class
for transformations). However, users have to usually implement
transformation rules, scheduling, tracing, and other facilities,
mostly from scratch in a programming language such as Java.
</p>

</blockquote></div>

<p>
However, we do provide the framework on which to implement the
transforms so that users do not have to worry about any of the
concerns listed above.
</p>
<ul class="org-ul">
<li>actually perhaps we take an hybrid approach. 1) we use direct
manipulation because the framework is defined in a GPL. 2) we also
use the structure-driven approach because we have similar phasing:
"Approaches in this category have two distinct phases: the first
phase is concerned with creating the hierarchical structure of the
target model, whereas the second phase sets the attributes and
references in the target. The overall framework determines the
scheduling and application strategy; users are only concerned with
providing the transformation rules." 3) clearly we have an
operational approach because we have more dedicated support for
model transformation (e.g. the dogen API).</li>
<li>our transforms are implemented as imperative rules: "A fully
imperative rule (so-called procedure) has a name, a set of formal
parameters, and an imperative block, but no patterns."</li>
<li></li>
</ul>
</div>
</div>

<div id="outline-container-orgde1a2f8" class="outline-2">
<h2 id="orgde1a2f8"><span class="section-number-2">32</span> Software Diversity: State of the Art and Perspectives</h2>
<div class="outline-text-2" id="text-32">
<ul class="org-ul">
<li><a href="papers/Software%20Diversity%20%E2%80%93%20State%20of%20the%20Art%20and%20Perspectives.pdf">paper</a></li>
<li>they focus on "anticipating variability". We believe it should not
be anticipated, but discovered and incorporated organically and
systematically into the system.</li>
<li>variability can either be planned or emergent. We believe in
emergent variability. Another pillar of fractal systems
development. Emergent does not imply implicit. You can make it
explicit.</li>
<li>the feature model of a general purpose, OO code generator lives in
problem space - i.e. the problem space of code generation. This is a
special case where the problem space and the solution space are the
same. In fact "general purpose" is not quite right: it is special
purpose in the sense its design to model only OO and features that
can be expressed as functional dependencies of structural models.</li>
<li>our approach seems to be this one: "annotative approaches or
superimposed variants representing negative variability—all variants
of the product line are included within the same model."</li>
<li>the key advantage of our approach is that instead of having to do
structural surgery to the model, we are simply switching facets on
or off. This is a much easier thing to achieve. "Variant annotations
define which parts of the model have to be removed to derive a
concrete product model."</li>
<li>its very important to split out the feature definition and the
feature use. For definition we can rely on overloading UML
(stereotypes, etc). However, we still need to figure out how to
solve the contraints problem (dependencies, etc). For use we can
simply rely on stereotypes and tagged values.</li>
<li>orthogonal variability model seems interesting. We could go for
capturing variability separate from the model, but variability
application does require the model. Here we are referring to code
generator variants.</li>
<li>we use a compositional approach to associate data with model
elements such as include files and metatype information.</li>
<li>they use the term "model fragment" on compositional
approaches. Perhaps proxy models are just model fragments.</li>
<li>so we use positive variability at the model level and negative
variability at the template level because facets are combined to
generate the complete model representation.</li>
<li>we seem to rely on both collaborative features (facets) as well as
aspectual features (helpers).</li>
<li>"Diversity interfaces and switches in Koala can be understood as
concrete language constructs targeted at the implementation level to
express variation points and associated variants."</li>
<li>"When modeling variability, features or decisions are just (problem
space) abstractions of the variability realized in real development
artifacts." However, this is not the case with code generators
because the problem space of the code generator is intertwined with
the solution space.</li>
<li>"Other variability modeling approaches define a separate artifact
model, which exposes artifact abstractions to the decision or
feature model". This seems to be what we are doing. We took
advantage of the fact that code generators are a bit special and
mapped the artefacts to the feature model (or vice-versa).</li>
<li>we need to read the lose programming paper to see if that is what we
are doing.</li>
<li>feature interaction analysis is interesting but it is beyond the e
scope of all the work we have outlined at present. Similarly with
model checking and deductive logic.</li>
<li>to some extend we are taking on the one thing approach (see
paper). Its just that our end customers are not the SPL end
customers but the code generator SPL end customers -
i.e. developers. This means we put the developer at the centre of
our concerns. In this light the one thing paper may be useful, most
likely for the Dogen manual. Our objective is not to make the
modeling of problem domain entities easier but to model solution
space / implementation level patterns that appear in the artefacts.</li>
<li>by controlling the entire pipeline we control the evolution and thus
can confine it somewhat and make sure all the parts fit. The
disadvantage is the limited developer pool to work on all the
aspects of the tool chain.</li>
<li>predictive vs opportunistic software reuse when using SPL</li>
</ul>
</div>
</div>

<div id="outline-container-orgeb9a9c5" class="outline-2">
<h2 id="orgeb9a9c5"><span class="section-number-2">33</span> Variability in Software Architecture: Current Practices and Challenges</h2>
<div class="outline-text-2" id="text-33">
<ul class="org-ul">
<li><a href="papers/Variability%20in%20Software%20Architecture:%20Current%20Practice%20and%20Challenges.pdf">paper</a></li>
<li>it seems that the scope of variability is too vast. We need
different strategies for different kinds of variability.</li>
<li>interestingly, the "welcome mat" approach is also related to
variability. That is, the support of multiple protocols (JSON, XML,
HTTP, etc) for comms, the packaging as a library (static, shared),
or as a component (COM, CORBA), or as a service, unbinding the UI
technology from the implementation so that multiple UIs can be
supported (Wt, GTK, Qt, TUI), etc are all variability concerns from
an architectural perspective. The product team is responsible for
enabling variability across most of these dimensions. What is
lacking is a taxonomy/classification of the different kinds of
variability.</li>
<li>the paper provides a method for identifying variation points at the
architectural level. It also provides an approach for analysing the
VPs.</li>
<li>functional core approach: define not just what varies in a product
but also what is constant. The functional core is the essence of the
product. We take this approach on Dogen. We need to define what we
consider to be part of the functional core and what is allowed to
vary. The functional core is what makes that product unique. Each
functional core must be well-understood, and cannot be too large. It
must be straightforward to decide if new functionality is in keeping
with the functional core or not. Its understanding will evolve over
time, incrementally.</li>
<li>its not necessarily the case that everything needs to be
automated/tooled around. Its useful to model variability separately
even if its not possible to make the most of those models; it means
everyone is conscious about introducing and documenting variability
into the system. It should not be taken lightly.</li>
<li>variability is a manifestation of indecision on a decision topic. If
there is a decision such as "do not include" then we do not need a
variation point. If there is a decision such "as always include"
then its likely to be added to the functional core (although
Savolainen disagrees and states that not all mandatory features are
part of the functional core; not clear how so).</li>
</ul>
</div>
</div>

<div id="outline-container-org3d685dc" class="outline-2">
<h2 id="org3d685dc"><span class="section-number-2">34</span> Systems Variability Modeling: A Textual Model Mixing Class and Feature Concepts</h2>
<div class="outline-text-2" id="text-34">
<ul class="org-ul">
<li><a href="papers/Systems%20Variability%20Modeling:%20A%20Textual%20Model%20Mixing%20Class%20and%20Feature%20Concepts.pdf">paper</a></li>
<li>definition of the feature model and the application (feature
configuration) are different things. We should split them with two
approaches: text based approach for the former, and model mixing for
the latter.</li>
<li>splitting features according to types is a good idea, but not sure
we agree on their classification.</li>
</ul>
</div>
</div>

<div id="outline-container-org517da62" class="outline-2">
<h2 id="org517da62"><span class="section-number-2">35</span> A Common Metamodel for Code Generation</h2>
<div class="outline-text-2" id="text-35">
<ul class="org-ul">
<li><a href="papers/A%20Common%20Metamodel%20for%20Code%20Generation.pdf">paper</a></li>
<li>very similar to previous paper.</li>
<li>We take a similar approach: "As has been outlined in [4], we use a
package with common meta- modelling building blocks for all our
metamodelling activities.  This makes it easier to speak about
common concepts under the same name, much as Design Patterns in
software engineering help programmers to talk about common
programming concepts."</li>
<li>they chose names similar to UML infrastructure; we have chosen names
that are different to ensure there is no confusion between language
concepts and modeling concepts, as well as not having problems with
reserved words.</li>
<li>they re-implemented UML infrastructure (parts of MOF that are in
UML?), and question whether to reuse it or re-implement it. We take
the view that whilst conceptually it is very useful, at the
implementation level it does not add any value.</li>
<li>there are differences between modeled languages (say namespaces /
packages); it is the role of the metamodel to normalise them and the
code generator to express them as idiomatically as possible.</li>
<li>we use the same approach of named elements, but we partitioned the
naming space.</li>
<li>they do not constrain elements to exist in packages; we more or less
do, although there are hacks to place things in the global
namespace. We need to clean this up.</li>
<li>due to normalisation (least common denominator) we also do not allow
multiple inheritance on data structures.</li>
<li>as the model is OO, there are limitations when modeling to non-OO
languages such as C. It is still possible though, and useful even
without support for operations.</li>
<li>we do not distinguish between collections at the metamodel
level. However, they link to aspects in the generator. At present we
do not support built-in collections (e.g. int[]). This is only
because the parsing engine does not parse them.</li>
<li>we do not model entry points such as main, etc at present. We could
in the future, but its better to simply bypass the dogen and create
files manually.</li>
<li>Java has package visibility, C# has internal visibility. Whilst we
do not have a way to model these, we could create the notion of
internal which in C++ means hide the header files and do not export
symbols. In C# use external. In java, ignore it.</li>
</ul>
</div>
</div>

<div id="outline-container-orgb1293bd" class="outline-2">
<h2 id="orgb1293bd"><span class="section-number-2">36</span> A Code Generation Metamodel for ULF-Ware</h2>
<div class="outline-text-2" id="text-36">
<ul class="org-ul">
<li><a href="papers/A%20Code%20Generation%20Metamodel%20for%20ULF-Ware.pdf">paper</a></li>
<li>extremely interesting paper, which tackles exactly the same problem
as dogen: "While code can be generated from any model, we propose to
use an intermediate model that is tailored to code generation
instead. In order to be able to easily support different target
languages, this model should be general enough; in order to support
the whole process, the model has to contain behavioural as well as
structural aspects."</li>
<li>however, they seem to also focus on behaviour. Worth seeing what
they have to say, but we are explicitly moving away from it.</li>
<li>"Generally, adding another library with the same interface does not
require new transformations." Similar to Dogen, except we also cater
for impedance mismatches between metamodel and the library. For this
we use an aspect oriented approach, where feature configuration is
used to bind aspects to elements.</li>
<li>they have decided to use MOF as their metamodel.  We have used UML
to define our metamodel. We need a good explanation for our approach
given its a lot less orthodox. We did not find the MOF types useful
to our model. Need to justify this.</li>
<li>crucial quote, totally applicable to us: "High-level models are
quite different from programs in conventional programming
languages. They abstract from most of the detail that a programming
language exhibits. Once you want to generate real code, all this
detail has to be filled in. This makes code generation from those
models a difficult task. Moreover, many decisions in this process
are similar for different target languages, but it is hard to make
use of these commonalities." Our key objective was to design a model
that modeled these aspects.</li>
<li>very important point on "close to the language but not too close":
"The reverse approach is to use models that are very low-level and
close to a specific language. There have been a number of papers
such as [6] implement- ing this. The metamodel obtained this way is
close to the original BNF of the language, they are grammars in
disguise. Models like this are difficult to obtain.  They would be
the result of a model transformation from a high-level model.  Here,
the intelligence would have to lie in the transformations."</li>
<li>the crux of our approach is encapsulated in this passage: "How will
this be represented in the model in a uniform fashion? One way is to
have special metamodel-elements for print- ing text, and similarly
for all the other library calls that differ; this also means changes
to the metamodel if we want to include another call. The other way
is to use a common runtime library that offers a uniform interface
to the model and encapsulates differing functionality; clearly, this
approach is superior."</li>
<li>our approach is to make use of the standard libraries or third-party
libraries available in languages but use templates and aspects as a
way to fix the impedance mismatch. This saves us from having
additional dependencies and makes programming more intuitive to the
natives of a language. We can use the adoption paper as a rationale
for why it is not a good idea to have a consistent API across
languages.</li>
<li>we need to explain why we wanted to support multiple
languages. Reasons: 1) make sure we are not hard-coding the
metamodel to just one language 2) expand the pool of contributors as
much as possible.</li>
<li>we created a level of abstraction from classes, modeling them
according to the types: value objects, enumerations, etc.</li>
<li>we do not support collections directly.</li>
<li>we do not have a fixed type of primitives. We do split the notion of
primitive and underlying primitive. This has to be explained in
great detail. We do not have constraints on the presence of
primitives, they are just handled like any other element.</li>
<li>we do not support functions or operations.</li>
<li>we use type mapping in order to create language agnostic models, and
(will) support user overriding.</li>
<li>our aims are also simple and readable code, using the language
idioms at all times or high-level constructs such as patterns.</li>
<li>our concept of system libraries and proxy libraries extends Piefel
and Neumann's concepts of library interfaces. We need to explain this.</li>
</ul>
</div>
</div>

<div id="outline-container-org9c7046c" class="outline-2">
<h2 id="org9c7046c"><span class="section-number-2">37</span> Aspect-Oriented Model-Driven Software Product Line Engineering</h2>
<div class="outline-text-2" id="text-37">
<ul class="org-ul">
<li><a href="papers/Aspect-Oriented%20Model-Driven%20Software%20Product%20Line%20Engineering.pdf">paper</a></li>
</ul>
</div>

<div id="outline-container-orgdd7f25a" class="outline-3">
<h3 id="orgdd7f25a"><span class="section-number-3">37.1</span> Expressing Variability in Structural Models</h3>
<div class="outline-text-3" id="text-37-1">
<ul class="org-ul">
<li>reference to czarnecki's paper on superimposed variants: "In [13],
the links are managed using stereotypes which requires invasive
changes to the model that should be tailored." We need to add this
to our list of disadvantages.</li>
<li>our approach of splitting the generational model from the modeling
model means that we do not have to worry about positive or negative
variability in the modeling (structural) space (well, not entirely
at any rate). Instead, it is (mostly) pushed down to the
generation/templates level, where it is easier to handle. In a way,
we disagree with Groher and Voelter's statements: "Variability can
be described more concisely since in addition to the traditional
mechanisms (e.g. patterns, frameworks, polymorphism), variability
can be described on the more abstract level of models." Our
generation model provides us a set of dimensions under which a model
can vary so that handling variability at the implementation level
becomes more manageable.</li>
<li>we moved towards the world of facets for exactly the same reason
that M2T has moved towards templates: it is the right mix of
abstraction and hard-coding. Somethings are just too verbose to
describe at the model level, such as serialisation. However, this
may be an artefact of our main target language (C++), because on
other languages such as C# we probably would rely more on aspects
and less on facets.</li>
<li>modeling space has a mapping from problem space to solution space. A
solution space model in a different representation will have a one
to one mapping to modeling space.</li>
<li>we specifically remove the ability to handle positive/negative
variability in the structural model to reduce complexity.</li>
<li>conclusion: we have limited support for structural variability, by
design. Or perhaps, we use structural variability only in one place,
and that is going from frontend models into the modeling
model. However, the variability is mainly concerned with type
mapping rather than proper variability (positive/negative). This is
still structural variability though since the modeling model will
<span class="underline">vary</span> according to the feature configuration selected by the user,
which is conveyed via UML facilities: stereotypes and tagged values.
Yet another take is that we use negative variability everywhere, but
it does not have a structural manifestation due to the
modeling/generation space split. In other words, users can switch
off facets (negative variability) but since facets do not have a
structural representation at the modeling level you cannot see
it. But this is clearly negative variability.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd39acba" class="outline-3">
<h3 id="orgd39acba"><span class="section-number-3">37.2</span> Expressing Variability in Model Transformations</h3>
<div class="outline-text-3" id="text-37-2">
<ul class="org-ul">
<li>the code generation feature model is expressed as code, and can be
queried by the model transformations. The model transformations are
hard-coded to the generation model, and are designed to provide all
the required queries. Extensions to queries requires changes to both
the metamodel and the transformations.</li>
<li>we only support one type of cross-metamodel transform: from frontend
metamodel to modeling metamodel.</li>
<li>most of our transforms are "in place transforms", called model
modifications rather than model transformations; that is, the
original model is modified. A few transforms such as merging do not
touch the inputs, so these are proper transforms. We need to explain
that we treat modifications and transforms the same way.</li>
<li>we code-generate the feature model, but every time a new feature is
added we need to manually update the affected transforms. This is
done to keep code generation easy to understand. Note that this is
feasible because this is not a general purpose code generator but a
special purpose code generator.</li>
</ul>
</div>
</div>

<div id="outline-container-orgd9c4595" class="outline-3">
<h3 id="orgd9c4595"><span class="section-number-3">37.3</span> Expressing Variability in Code Generation Templates</h3>
<div class="outline-text-3" id="text-37-3">
<ul class="org-ul">
<li>As with transformation, we access the feature model directly and
changes must be done manually.</li>
<li>we use stitch and stitch2 to generate regular c++ code that is human
readable, debuggable etc. Developers do not need to learn a new
toolset.</li>
<li>we use AO for handling variability just for one case: helpers. The
objective is to reduce the amount of third party code needed to
solve the impedance mismatch between generated code and supporting
libraries. The rest is handled by hard-coding the code generator
feature model into the templates. This is done by design.</li>
<li>we could use "feature casting": create a base class for features (or
feature groups, check terminology). Users request the feature (or
group) via its path, and the template function takes a type
parameter for the casting. It could return an optional, if the
feature is optional.Annoyingly this is not required for "core"
features because we can see the type definition, but if we use this
pattern everywhere, it means users can add their own features,
register them, and consume them from their templates.</li>
</ul>
</div>
</div>

<div id="outline-container-orgc4b0db3" class="outline-3">
<h3 id="orgc4b0db3"><span class="section-number-3">37.4</span> Expressing Variability in Code</h3>
<div class="outline-text-3" id="text-37-4">
<ul class="org-ul">
<li>mainly by use of apsects and integrating them with the feature
model. Use of comments allows code generator to remove code that is
not required. Interestingly, this could be done via our proposed
merging approach: protected regions could be annotated with
additional attributes, and these could be linked to features. During
generation we could not express the protected regions for which the
features have not been switched on. However, we do not have a use
case for this. Also its not clear where the protected regions would
be stored - the code generation product line vs software product
line split is a bit confusing.</li>
</ul>
</div>
</div>

<div id="outline-container-org24e6bbd" class="outline-3">
<h3 id="org24e6bbd"><span class="section-number-3">37.5</span> Home Automation Case Study</h3>
<div class="outline-text-3" id="text-37-5">
<ul class="org-ul">
<li>it is still not clear why we need to resort to DSLs in order to
create unique products when we could just as well treat each product
in a product line as data and have rules for specific
configurations. This seems to be the case with the home automation.</li>
<li>in addition, the PIM to PSM transformation, could also be thought of
as parameterisation in variability space. That is, we could simply
have a set of mappings that determine platform specific
implementations (component technology, programming language, etc)
which are chosen by the user (via feature configuration). Then, we
go from PIM directly to code. This simplistic approach is more
adequate to new MDE users. The PIM to PSM options are canned, but
extensible, the hard-way: add your own plugin, provide a new facet,
select it on your feature configuration.</li>
<li>orthogonal variability: variability which is not dependent on to the
problem space model instance - e.g. applies regardless of the
specific configuration. "By orthogonal we mean variability that
affects multiple domain entities and their subsequent processing
(i.e. transformation) steps."</li>
<li>reflection layer seems to be useful to generate a GUI at
runtime. However, it seems easier to map GUI elements at generation
time, and then determine which dialogues are available in the UI
depending on the presence of elements of the problem space model.</li>
<li>configurative variability: this seems to be the technical term for
using data to manage variability. Our approach is to push a lot of
structural variability into configurative variability, so that the
end users of the system need to deal with it rather than the
developers. Actually, configurative variability can be realised by
structural variability.</li>
<li>"The higher the abstraction level is, the fewer variation points
exist. Features expressed on models level are thus inherently
simpler than features expressed on code generation level. We
therefore argue to always express features on the highest possible
level."</li>
</ul>
</div>
</div>

<div id="outline-container-orgc6036a3" class="outline-3">
<h3 id="orgc6036a3"><span class="section-number-3">37.6</span> Conclusions</h3>
<div class="outline-text-3" id="text-37-6">
<ul class="org-ul">
<li>"The higher the abstraction level is, the fewer variation points
exist. Features expressed on models level are thus inherently
simpler than features expressed on code generation level. We
therefore argue to always express features on the highest possible
level." - however, there is still a trade-off: by expressing
features in the model and producing structural transformations, we
then push the complexity to the transforms and templates. We should
distinguish between features that have a good structural
representation from features that are trivial functions of structure
such as serialisation, test data generation, etc. For these, it
makes more sense not to represent them structurally but instead have
the variation points expressed at the template level.</li>
<li>this raises an interesting point:</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-orgdc4f6cb" class="outline-2">
<h2 id="orgdc4f6cb"><span class="section-number-2">38</span> An Aspect-Oriented and Model-Driven Approach for Managing Dynamic Variability</h2>
<div class="outline-text-2" id="text-38">
<ul class="org-ul">
<li><a href="papers/An%20Aspect-Oriented%20and%20Model-Driven%20Approach%20for%20Managing%20Dynamic%20Variability.pdf">paper</a></li>
<li>describes a framework to dynamically generate valid
configurations.</li>
<li>uses a metamodel to describe AOM, allowing the application of
aspects dynamically to a model (called SMART ADAPTERS)</li>
<li>computes diff and match models and then based on that outputs a
configuration. The configuration can then be validated before its
applied. All of this is done at run time so for systems where
configuration transitions need to be quick (or predictable), this is
not suitable out of the box. They suggest pre-computing critical
configurations up front (at startup?)</li>
<li>does not seem to be directly applicable to Dogen: the code generator
itself does not have a need for "discovery". Applications built with
it may have such a need, but its not obvious creating a reflection
based mechanism, plus AOM etc is the most straightforward way of
handling this. We need a specific use case in order to frame this
paper.</li>
<li>in general, we do not have a requirement for dynamic
variability. Well, we do but it is handled via plugins etc. We have
a limited requirement for this. Our aim is to reduce the variability
surface area so that we reduce the complexity associated with
handling it.</li>
</ul>
</div>
</div>

<div id="outline-container-org8ae7f29" class="outline-2">
<h2 id="org8ae7f29"><span class="section-number-2">39</span> A Feature Model for Model-to-Text Transformation Languages</h2>
<div class="outline-text-2" id="text-39">
</div>

<div id="outline-container-org3f4cc46" class="outline-3">
<h3 id="org3f4cc46"><span class="section-number-3">39.1</span> Abstract</h3>
<div class="outline-text-3" id="text-39-1">
<ul class="org-ul">
<li>it seems like the main contribution of this paper is a feature model
for M2T languages. This is useful so we can justify out choices in
Stitch2.</li>
</ul>
</div>
</div>

<div id="outline-container-org79c910a" class="outline-3">
<h3 id="org79c910a"><span class="section-number-3">39.2</span> Introduction</h3>
<div class="outline-text-3" id="text-39-2">
<ul class="org-ul">
<li>migrating M2T languages is very difficult. Effectively its a form of
vendor lock-in. Its easier to just rewrite than to port.</li>
<li>most M2T languages are template based. There are other types though
(visitor pattern based, explicit printing of statements). Paper only
focuses on template based.</li>
<li>their paper helps users that want to select a M2T language.</li>
</ul>
</div>
</div>

<div id="outline-container-org297aa12" class="outline-3">
<h3 id="org297aa12"><span class="section-number-3">39.3</span> A Feature Model for M2T Languages</h3>
<div class="outline-text-3" id="text-39-3">
<ul class="org-ul">
<li>Their work is largely based on Czarnecki and Helsen's, but they
considered template based M2T a degenerate case whereas Rose etal
consider it the most significant case.</li>
<li>they use FeatureIDE to draw their feature diagrams. It is eclipse
based.</li>
<li>transformation style: imperative or declarative.</li>
<li>templates: direction of escaping (is the code escaped or is the
template escaped), typed templating language, textual templating
language.</li>
<li>output: destination of the output - normally to file?
post-processing: clang format, protected region handling.</li>
<li>modularity mechanisms: template reuse. Here we provide only a single
way of reusing a template, the aspect approach. The idea is that for
specific types we may need to inject additional functionality. This
is not meant as a generic reuse mechanism, instead for this users
should use copy &amp; paste.</li>
<li>tracing: how to relate the template to the generated code. Note that
we are not talking about the transformation from template into C++
code capable of generating a file, but the end file. Its as if we
need two levels of tracing here.</li>
<li>incrementality: the way the transformation is executed in response
to changes to the source model. Ideally we should have a separation
between the internal generation of the code and the updating of
files in the file system.</li>
<li>directionality: normally uni-directional, e.g. from model to text.</li>
<li>tools: not clear, does not include IDE with syntax highlighting and
debugging.</li>
</ul>
</div>
</div>
</div>

<div id="outline-container-org5f1a27b" class="outline-2">
<h2 id="org5f1a27b"><span class="section-number-2">40</span> Modeling Variability in Template-based Code Generators for Product Line Engineering</h2>
<div class="outline-text-2" id="text-40">
<ul class="org-ul">
<li><a href="papers/Modeling%20variability%20in%20template-based%20code%20generators%20for%20product%20line%20engineering.pdf">paper</a></li>
<li>how to model variability using Variability Regions instead of Aspect
Oriented Programing.</li>
</ul>
</div>

<div id="outline-container-orgf775cf6" class="outline-3">
<h3 id="orgf775cf6"><span class="section-number-3">40.1</span> Abstract</h3>
<div class="outline-text-3" id="text-40-1">
<ul class="org-ul">
<li>we need to define what is meant by variant.</li>
<li>what is meant by "adaptable and extensible"? What are the dimensions
under which we "adapt and extend"?</li>
<li>authors are critical, but being fixed to a set of features is not
necessarily a bad thing, if there is good support out of the box.</li>
<li>the key point seems to be a mapping of features to Variability
Regions (VRs), and having dependency management amongst VRs.</li>
<li>we need a good discussion on why VRs are better than aspects, and
how they relate.</li>
</ul>
</div>
</div>

<div id="outline-container-org3390b34" class="outline-3">
<h3 id="org3390b34"><span class="section-number-3">40.2</span> Introduction</h3>
<div class="outline-text-3" id="text-40-2">
<ul class="org-ul">
<li>paper is critical of monolithic code generators, but there are
advantages; they are a lot simpler. Also, its important to think of
reuse as a dimensional space. We can facilitate some kinds of reuse
whilst precluding others in the search for lowering complexity.</li>
<li>interestingly, they seem to imply that both Acceleo and Xtend have
an approach of handling variability which relies on "language
specific approaches for implementing variability, e.g. design
patterns." This ties in with the <a href="papers/Handling%20Variability%20in%20Model%20Transformations%20and%20Generators.pdf">Voelter paper</a>.</li>
<li>the paper focuses on Code Generator Product Lines, designed
specifically to handle variability in code generators. Their
approach is based on Variability Regions and they state that these
can be applied to any code generator.</li>
<li>layers are an extension of the feature oriented programming (FOP)
concept, applied to code generation templates. They define how
parts of a template or an entire template can be resued within
layers. The key point is to decouple the concepts from the template
technology, so that they can be applied to any code generator. This
seems extremely useful for Dogen.</li>
</ul>
</div>
</div>

<div id="outline-container-org8576a0b" class="outline-3">
<h3 id="org8576a0b"><span class="section-number-3">40.3</span> Variability Concepts in Code Generator Product Lines</h3>
<div class="outline-text-3" id="text-40-3">
<ul class="org-ul">
<li>we are creating a Code Generator Product Line (CGPL). This is quite
confusing. Basically we do not give end users a code generator; we
give them a "template" with which to create specific code generators
for their use case. The customisation of the code generator is done
via the variability mechanisms we make available to them, which at
present are:
<ul class="org-ul">
<li>structural: object templates, stereotypes such as visitor,
enumeration etc.</li>
<li>non-structural: all of the dogen machinery to customise a model
such as adding licences, comments on or off (not yet implemented),
enabling of facets, etc.  When we finally implement "profiles" on
top of stereotypes, this will also be a non-structural mechanism,
even though it spans structure (users define classes, which are
associated with stereotype (the class name) and toggle features
on/off).</li>
</ul></li>
<li>a concrete code generator product is called a Variant. A CGPL is
like a Software Product Line (SPL) factory, because it generates
concrete code generators. These then generate SPLs?</li>
<li>FOP is an approach to implement SPLs that is based on building
software systems by composing features. A feature represents a
configurable unit of a software system that represents a
requirement-satisfying design decision. Features are arranged in
layers that contain artefacts. These artefacts appear to be
templates. Artefacts may refine multiple other artefacts. However,
it seems the paper puts java classes and layers on the same
plane. It seems they make the distinction between "code generated
artefacts" and others. Code generator layers are used for code
generator artefacts.</li>
<li>also, its not obvious why we need both VRs and layers. We could
simply say that a template is made up of a set of VRs, and the VRs
are switched on or off based on feature configuration. This is
slightly better than AOP because we don't need all of the AOP
machinery (cross-cutting concerns, joint points, etc).</li>
<li>if we map this model to Dogen, a stitch template becomes an
artefact, and helpers then provide a way to "compose"
templates. Facets "map" the feature (e.g. boost serialisation) to
the artefact (e.g. template implementing boost serialisation). We
have transported the feature configuration into the code generation
metamodel and the assistant by adding generation specific types to
it: <code>requires_hashing_helper</code> etc. The key problem is that in Dogen
we do not have a concept of Variability Regions nor will it be easy
to implement because it would require dramatic changes to
stitch. Also the "conditions" for each VR can be quite complex. Its
not clear what advantages we'd gain from VRs in Dogen. The
addressability of VRs is quite interesting, but not clear how we'd
make use of it to improve things. We could possibly make a
description of the model of the template as a set of named
variability regions with associated predicates, but then explain
that implementation-wise, its more sensible to code it by hand given
the target audience.</li>
<li>we need to have a section on "informal reuse" / copy and paste reuse.</li>
<li>we need to do a write up of why we think that the increase in
complexity by having a layer/feature DSL is not a good fit for an
entry-level code generator product line. We need to make the case
for keeping templates quite close to regular code.</li>
<li>interesting paper: <a href="https://link.springer.com/book/10.1007%252F978-3-642-37521-7">Feature-Oriented Software Product Lines: Concepts
and Implementation</a>. However seems to be behind a paywall.</li>
<li>commands in layer DSL: define a layer, VR replaces other VR, appears
before or after a VR.</li>
</ul>
</div>
</div>

<div id="outline-container-orgec61f0f" class="outline-3">
<h3 id="orgec61f0f"><span class="section-number-3">40.4</span> Code Generator Variant Configuration and Generation</h3>
<div class="outline-text-3" id="text-40-4">
<ul class="org-ul">
<li>a CGPL consists of a number of layers, and each layer contains a
number of templates.</li>
<li>their approach works more like a library, where concrete CGPL reuse
the basic infrastructure to create the specific CGPL the user is
interested in. This allows for both a high degree of reuse and a
high degree of configurability. The downside is complexity, because
the user needs to understand two DSLs.</li>
<li>Layer Definition Language (LDL) is the DSL created to model the
layer operations.</li>
<li>variant configuration: we need to ensure the set of layers generates
a valid configuration. They use a coloured graph to do this. The
graph must be acyclic, and they do not support multiple
inheritance. We could probably use a similar approach for features.</li>
<li>in their case: "based on the layer definition model and the product
configuration model, a concrete code generation variant is created."
In our case, this is done at dogen run time. Code generator variants
are a function of the product configuration model which is embedded
in the structural model. Variation is constrained in order to
achieve this. Composition / layering is achieved not at the template
level but at the facet level. Actually perhaps what we are saying is
that facets are the layers and we explicitly move them away from the
template / file level to tame complexity. We make use of a fixed set
of layers but we use them at a higher conceptual level. Variability
Regions are no longer required at the layer level - we vary by the
entire layer at this level. We can then make an argument for a) why
layers at the artefact level is the wrong approach if you are
optimising to reduce complexity b) the downside of losing some
object orientation by moving responsibility across to other classes,
not a problem in hybrid languages like C++ or procedural languages
like C but a problem in Java/C#.</li>
<li>in this case we can then say we use exactly the same approach for
the creation of concrete variants (e.g. coloured graph). We need to
also add how we allow variation at the metamodel element instance
level.</li>
<li>transitivity is an issue for layers as is an issue for facets. We
need to reuse their approach.</li>
<li>the run time of the code generator is called generation time. All
our operations are executed at generation time. Perhaps we should
name our variants generation time variants.</li>
<li>we need to make a case for stitch as a template language very close
to a general purpose language. We need to compare it to Xpand.</li>
</ul>
</div>
</div>

<div id="outline-container-org5bd4da5" class="outline-3">
<h3 id="org5bd4da5"><span class="section-number-3">40.5</span> Demonstrating Example for Variability Regions</h3>
<div class="outline-text-3" id="text-40-5">
<ul class="org-ul">
<li>terminology: we describe templates as "archetypes" whereas they seem
to call them artefacts (or somehow artefacts are related to
templates). In our model, empty VRs do not make sense nor do empty
layers. We have multiple archetypes to express a given
metatype. These form layers (e.g. what we called facets).</li>
<li>the problem with using comments to mark VRs are mentioned, and they
seem to be exactly the same as with protected regions.</li>
<li>Xpand's way of allowing method definitions "out of order" makes
templates much harder to read - e.g. to visualise what the output of
the template will be.</li>
</ul>
</div>
</div>

<div id="outline-container-org752cdc6" class="outline-3">
<h3 id="org752cdc6"><span class="section-number-3">40.6</span> Industrial Case Study</h3>
<div class="outline-text-3" id="text-40-6">
<ul class="org-ul">
<li>generation of inner classes: this can be handled easily by metadata
and using namespaced names on the structural representation.</li>
<li>classes tagged with a stereotype instead of generating regular
fields, generate "special" fields.</li>
<li>suffixes added to class names: this should be a metadata parameter
to the code generator.</li>
<li>their research questions are very good, and very measurable. The
approach of doing "old way" and "new way" and comparing the results
is very effective. Its not so easy for us to do this, but if we
could it would be a major selling point.</li>
<li>we need to somehow state that our approach allows a large number of
CGPL to be generated via generation time configuration without any
need to copy &amp; paste reuse nor the complexity of a general purpose
VR mechanism. If we could find a project that is already using say
EMF and prove that with just our code generator out of the box (plus
minor alterations) we could generate the same code we would have
"proof".</li>
</ul>
</div>
</div>

<div id="outline-container-org1ed7d14" class="outline-3">
<h3 id="org1ed7d14"><span class="section-number-3">40.7</span> Related Work</h3>
<div class="outline-text-3" id="text-40-7">
<ul class="org-ul">
<li>here they provide a taxonomy of approaches to express variability in
the solution space. We need to classify our approach against these:
<ul class="org-ul">
<li>annotative: specify all variants in one model.</li>
<li>compositional: combine different model fragments to derive a
specific variant.</li>
<li>delta modeling: applies transformations to a core model</li>
</ul></li>
<li>these approaches seem to overlap with Positive and Negative
variability.</li>
<li>dogen seems to use a combination of annotational (metadata tags) and
compositional (profiles are defined separately). Once we move
profiles into the models, these become annotational.</li>
<li>seems important to have the concept of VRs at the template level.</li>
<li>we seemed to have followed the Groher approach by handling all
structural differences on model level by the transformation
layer. We should discuss this.</li>
<li>we explicitly do not allow dynamic overriding of parts of a
template, but allow users to override an entire layer (e.g. facet)
with their own implementation located somewhere else in generation
space (actually it could also be in the same location in space, but
we need some handling to give higher priority of user templates over
system templates). In this sense we have copied the acceleo
approach, but we do so by generating a DLL and injecting it to the
code generator. This generates further CGPLs. Users can create
templates via the copy &amp; paste reuse. However, we strongly suggest
this as the last case scenario, when a user has very specific
requirements which cannot be reconciled with the majority of the
user base.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2021-02-28 Sun 11:20</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
